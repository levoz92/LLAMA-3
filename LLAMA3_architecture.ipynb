{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ThlnYK5jul2E"
      },
      "outputs": [],
      "source": [
        "import torch, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, List\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "with open('./tiny_shakespeare.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "vocab = sorted(list(set(data))) # Prep vocabulary by taking all unique chars from tiny_shakespeare.txt\n",
        "\n",
        "# llama3 requires additional tokens such as below\n",
        "vocab.extend(['<|begin_of_text|>','<|end_of_text|>','<|pad_id|>'])\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "itos = {i:ch for i, ch in enumerate(vocab)}\n",
        "stoi = {ch:i for i, ch in enumerate(vocab)}\n",
        "\n",
        "# tokenizers encode function: Takes a string, outputs a list of integers\n",
        "def encode(s):\n",
        "    return [stoi[ch] for ch in s]\n",
        "\n",
        "# tokenizers decode function: takes a list of ints and outputs a string\n",
        "def decode(l):\n",
        "    return ''.join(itos[i] for i in l)\n",
        "\n",
        "# tensor toke variables to be used later during training\n",
        "token_bos = torch.tensor([stoi['<|begin_of_text|>']], dtype=torch.int, device=device)\n",
        "token_eos = torch.tensor([stoi['<|end_of_text|>']], dtype=torch.int, device=device)\n",
        "token_pad = torch.tensor([stoi['<|pad_id|>']], dtype=torch.int, device=device)\n",
        "\n",
        "# Test\n",
        "prompts = 'Hello World'\n",
        "encoded_tokens = encode(prompts)\n",
        "decoded_text = decode(encoded_tokens)\n",
        "\n",
        "print(f\"Lenth of shakespeare in character: {len(data)}\")\n",
        "print(f\"The vocabulary looks like this: {''.join(vocab)}\\n\")\n",
        "print(f\"Vocab size: {vocab_size}\")\n",
        "print(f\"encoded_tokens: {encoded_tokens}\")\n",
        "print(f\"decoded_text: {decoded_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPMaoyuqyiw5",
        "outputId": "f95b1f46-2682-42bd-c195-d5b8b4c7f028"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenth of shakespeare in character: 1115394\n",
            "The vocabulary looks like this: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz<|begin_of_text|><|end_of_text|><|pad_id|>\n",
            "\n",
            "Vocab size: 68\n",
            "encoded_tokens: [20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42]\n",
            "decoded_text: Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSNorm\n",
        "# We are using RMSNorm to reduce computational overhead by avoiding the calculation of mean and variance.\n",
        "# RMSNorm gives performance advantages while not compromising on accuracy.\n",
        "\n",
        "@dataclass\n",
        "class ModelArgs:\n",
        "    dim: int = 512                                                      # embedding dimension\n",
        "    n_layers: int = 8                                                   # number of model decoder blocks\n",
        "    n_heads: int = 8                                                    # number of heads for queries embedding\n",
        "    n_kv_heads: int = 4                                                 # number of heads for keys and values embedding\n",
        "    vocab_size: int = len(vocab)                                        # length of vocabulary\n",
        "    multiple_of: int = 256                                              # Required to calculate the dim of feedforward network\n",
        "    ffn_dim_multiplier: Optional[float] = None                          # Required to calculate the dim of feedforward network\n",
        "    norm_eps: float = 1e-5                                              # Default Epsilon value set for the RMSNorm calculation\n",
        "    rope_theta: float = 10000.0                                         # Default theta value for the RoPE calculation\n",
        "\n",
        "    max_batch_size: int = 10                                            # max batch size\n",
        "    max_seq_len: int = 256                                              # max sequence length\n",
        "\n",
        "    epochs: int = 2500                                                  # total number of training iteration\n",
        "    log_interval: int = 10                                              # number of interval to print the logs and loss va;ues\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'        # assigning available device"
      ],
      "metadata": {
        "id": "QjTKx7ZN1o9r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        device = ModelArgs.device\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim).to(device))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(dim=-1, keepdim=True) + self.eps).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "# Test\n",
        "x = torch.randn((ModelArgs.max_batch_size, ModelArgs.max_seq_len, ModelArgs.dim), device=device)\n",
        "rms_norm = RMSNorm(dim=ModelArgs.dim)\n",
        "x_norm = rms_norm(x)\n",
        "\n",
        "print(f\"Shape of x: {x.shape}\")\n",
        "print(f\"Shape of x_norm: {x_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPDh1PXc32Vk",
        "outputId": "881e957c-a5d2-4719-b820-7e76395b234d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: torch.Size([10, 256, 512])\n",
            "Shape of x_norm: torch.Size([10, 256, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RoPE encoding\n",
        "\n",
        "def precompute_freqs_cis(dim: int, seq_len: int, theta: float=10000.0):\n",
        "    device = ModelArgs.device\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2, device=device)[:(dim//2)].float()/dim)) # computing theta value for each dim pair, which is dim/2\n",
        "    t = torch.arange(seq_len, dtype=torch.float32, device=device) # computing range of positions(m) in the sequence\n",
        "    freqs = torch.outer(t,freqs).to(device) # freqs gives all the theta value range for all the position of tokens in the sequence\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs).to(device), freqs).to(device) # this is the rotation matrix that needs to be converted to polar form in order to perform rotation to the embedding\n",
        "    return freqs_cis\n",
        "\n",
        "def reshape_for_broadcast(freqs_cis, x):\n",
        "    ndim = x.ndim\n",
        "    assert 0 <= 1 < ndim\n",
        "    assert freqs_cis.shape == (x.shape[1], x.shape[-1]) # the last two dimension of freqs_cis, x must watch\n",
        "    shape = [d if i==1 or i==ndim-1 else 1 for i,d in enumerate(x.shape)]\n",
        "    return freqs_cis.view(*shape)\n",
        "\n",
        "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
        "    device = ModelArgs.device\n",
        "    # Applying rotary positional encoding to both query and key embedding together\n",
        "    # First: The last dimension of xq and xk embedding needs to be reshaped to make it a pair. As rotation matrix is applied to each pair of dim.\n",
        "    # Next: Convert both xq and xk to complex number as the rotation matrix is only applicable to complex number\n",
        "\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2)).to(device)\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2)).to(device)\n",
        "\n",
        "    # The rotation matrix (freqs_cis) dimensions across seq_len(dim=1) and head_dim(dim=3) should match with the embedding\n",
        "    # Also, the shape freqs_cis should be the same with xq and xk, hence change the shape of freqs_cis:[seq_len,head_dim] -> freqs_cis:[1,seq_len,1,head_dim]\n",
        "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "\n",
        "    # performing the rotation operation by multiplying with freqs_cis\n",
        "    # after, converting both xq_out and xk_out back to real number and return\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3).to(device)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3).to(device)\n",
        "\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "head_dim = ModelArgs.dim//ModelArgs.n_heads\n",
        "wq = nn.Linear(ModelArgs.dim, ModelArgs.n_heads * head_dim, bias=False, device=device)\n",
        "wk = nn.Linear(ModelArgs.dim, ModelArgs.n_kv_heads * head_dim, bias=False, device=device)\n",
        "xq = wq(x_norm)\n",
        "xk = wk(x_norm)\n",
        "print(f\"xq.shape: {xq.shape}\")\n",
        "print(f\"xk.shape: {xk.shape}\")\n",
        "\n",
        "xq = xq.view(xq.shape[0],xq.shape[1],ModelArgs.n_heads, head_dim)\n",
        "xk = xk.view(xk.shape[0],xk.shape[1],ModelArgs.n_kv_heads, head_dim)\n",
        "print(f\"xq.re-shape: {xq.shape}\")\n",
        "print(f\"xk.re-shape: {xk.shape}\")\n",
        "\n",
        "freqs_cis = precompute_freqs_cis(dim=head_dim, seq_len=ModelArgs.max_seq_len)\n",
        "print(f\"freqs_cis.shape: {freqs_cis.shape}\")\n",
        "\n",
        "xq_rotate, xk_rotate = apply_rotary_emb(xq, xk, freqs_cis)\n",
        "print(f\"xq_rotate.shape: {xq_rotate.shape}\")\n",
        "print(f\"xk_rotate.shape: {xk_rotate.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmyxnkCP4iSE",
        "outputId": "d006a538-e820-40fb-efd3-2233736ac26f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xq.shape: torch.Size([10, 256, 512])\n",
            "xk.shape: torch.Size([10, 256, 256])\n",
            "xq.re-shape: torch.Size([10, 256, 8, 64])\n",
            "xk.re-shape: torch.Size([10, 256, 4, 64])\n",
            "freqs_cis.shape: torch.Size([256, 32])\n",
            "xq_rotate.shape: torch.Size([10, 256, 8, 64])\n",
            "xk_rotate.shape: torch.Size([10, 256, 4, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Query Attention"
      ],
      "metadata": {
        "id": "R1gSMSDn5f6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The Attention Block [Step2c: The KV Cache; Step2d: Group Query Attention]\n",
        "## As mentioned before, the naming convention follows original the meta's LLama3 GitHub\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, args: ModelArgs):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        # Embedding dimension\n",
        "        self.dim = args.dim\n",
        "        # Number of heads assigned to Query\n",
        "        self.n_heads = args.n_heads\n",
        "        # Number of heads assigned to Key and values. If \"None\", the number will be same as Query.\n",
        "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
        "        # Dimension of each head relative to model dimension\n",
        "        self.head_dim = args.dim // args.n_heads\n",
        "        # Number of repetition in order to make time Key, Value heads to match Query heads number\n",
        "        self.n_rep = args.n_heads // args.n_kv_heads\n",
        "\n",
        "        # Weight initialize for Keys, Querys, Values and Oupt. Notice that the out_feature value of weight for q and kv are based on it's heads\n",
        "        self.wq = nn.Linear(self.dim, self.n_heads * self.head_dim, bias=False, device=device)\n",
        "        self.wk = nn.Linear(self.dim, self.n_kv_heads * self.head_dim, bias=False, device=device)\n",
        "        self.wv = nn.Linear(self.dim, self.n_kv_heads * self.head_dim, bias=False, device=device)\n",
        "        self.wo = nn.Linear(self.n_heads * self.head_dim, self.dim, bias=False, device=device)\n",
        "\n",
        "        # Initialize caches to store Key, Values at start. (KV Cache Implementation)\n",
        "        self.cache_k = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim), device=args.device)\n",
        "        self.cache_v = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim), device=args.device)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, start_pos, inference):\n",
        "        # Shape of the input embedding: [bsz,seq_len,dim]\n",
        "        bsz, seq_len, _ = x.shape\n",
        "        # Mask will be used during 'Training' and is not required for 'inference' due to the use of KV cache.\n",
        "        mask = None\n",
        "\n",
        "        xq = self.wq(x)  #x[bsz,seq_len,dim]*wq[dim,n_heads * head_dim] -> q[bsz,seq_len,n_heads * head_dim]\n",
        "        xk = self.wk(x)  #x[bsz,seq_len,dim]*wq[dim,n_kv_heads * head_dim] -> k[bsz,seq_len,n_kv_heads * head_dim]\n",
        "        xv = self.wv(x)  #x[bsz,seq_len,dim]*wq[dim,n_kv_heads * head_dim] -> v[bsz,seq_len,n_kv_heads * head_dim]\n",
        "\n",
        "        # Reshaping Querys, Keys and Values by their number of heads. (Group Query Attention Implementation)\n",
        "        xq = xq.view(bsz, seq_len, self.n_heads, self.head_dim)      #xq[bsz,seq_len,n_heads, head_dim]\n",
        "        xk = xk.view(bsz, seq_len, self.n_kv_heads, self.head_dim)   #xk[bsz,seq_len,n_kv_heads, head_dim]\n",
        "        xv = xv.view(bsz, seq_len, self.n_kv_heads, self.head_dim)   #xv[bsz,seq_len,n_kv_heads, head_dim]\n",
        "\n",
        "        # Model - Inference Mode: kv-cache is enabled at inference mode only.\n",
        "        if inference:\n",
        "          # Compute rotation matrix for each position in the sequence\n",
        "          freqs_cis = precompute_freqs_cis(dim=self.head_dim, seq_len=self.args.max_seq_len * 2)\n",
        "          # During inferencing, we should only take the rotation matrix range from the current position of the tokens.\n",
        "          freqs_cis = freqs_cis[start_pos : start_pos + seq_len]\n",
        "          # Apply RoPE to Queries and Keys embeddings\n",
        "          xq, xk = apply_rotary_emb(xq, xk, freqs_cis)\n",
        "\n",
        "          self.cache_k = self.cache_k.to(xq)\n",
        "          self.cache_v = self.cache_v.to(xq)\n",
        "          # Store Keys and Values token embedding into their respective cache [KV Cache Implementation]\n",
        "          self.cache_k[:bsz, start_pos:start_pos + seq_len] = xk\n",
        "          self.cache_v[:bsz, start_pos:start_pos + seq_len] = xv\n",
        "\n",
        "          # Assign all the previous tokens embeddings upto current tokens position to Keys and Values variable for Attention Calculation\n",
        "          keys = self.cache_k[:bsz, :start_pos + seq_len]\n",
        "          values = self.cache_v[:bsz, :start_pos + seq_len]\n",
        "\n",
        "          # At this point, they Keys and Values shape aren't same with Queries Embedding which has to be in order to computer attention score\n",
        "          # Use repeat_kv function to make Keys,Values shape same as queries shape\n",
        "          keys = repeat_kv(keys, self.n_rep)      #keys[bsz,seq_len,n_heads,head_dim]\n",
        "          values = repeat_kv(values, self.n_rep)  #values[bsz,seq_len,n_heads,head_dim]\n",
        "\n",
        "        # Mode - Training mode: KV-Cache not implemented\n",
        "        else:\n",
        "          # Compute rotation matrix and apply RoPE to queries and keys for for training.\n",
        "          freqs_cis = precompute_freqs_cis(dim=self.head_dim, seq_len=self.args.max_seq_len)\n",
        "\n",
        "          #xq[bsz,seq_len,n_heads, head_dim], xk[bsz,seq_len,n_heads, head_dim]\n",
        "          xq, xk = apply_rotary_emb(xq, xk, freqs_cis)\n",
        "\n",
        "          # Use repeat_kv function to make Keys,Values shape same as the queries shape\n",
        "          #keys[bsz,seq_len,n_heads,head_dim], #values[bsz,seq_len,n_heads,head_dim]\n",
        "          keys = repeat_kv(xk, self.n_rep)\n",
        "          values = repeat_kv(xv, self.n_rep)\n",
        "\n",
        "          # For training mode, we'll compute mask and apply to the attention score later\n",
        "          mask = torch.full((seq_len, seq_len),float(\"-inf\"),device=self.args.device)\n",
        "          mask = torch.triu(mask, diagonal=1).to(self.args.device)\n",
        "\n",
        "        # To compute attention, we'll need to perform a transpose operation to reshape all queries, keys and values bring heads at dim 1 and seq at dim 2\n",
        "        xq = xq.transpose(1,2)                  #xq[bsz,n_heads,seq_len,head_dim]\n",
        "        keys = keys.transpose(1,2)              #keys[bsz,n_heads,seq_len,head_dim]\n",
        "        values = values.transpose(1,2)          #values[bsz,n_heads,seq_len,head_dim]\n",
        "\n",
        "        # Computing attention score\n",
        "        scores = torch.matmul(xq, keys.transpose(2,3)).to(self.args.device)/math.sqrt(self.head_dim)\n",
        "        if mask is not None:\n",
        "          scores = scores + mask\n",
        "\n",
        "        # Apply softmax to the attention score\n",
        "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
        "        # Matrix multiplication of attention score with the values\n",
        "        output = torch.matmul(scores, values).to(self.args.device)\n",
        "\n",
        "        # We get the contextual embedding for each head\n",
        "        # All heads need to be reshaped back and combined to give a single single contextual attention output\n",
        "        # Shape change: output[bsz,n_heads,seq_len,head_dim] -> output[bsz,seq_len, n_heads,head_dim] -> output[bsz,seq_len, n_heads * head_dim]\n",
        "        output = output.transpose(1,2).contiguous().view(bsz, seq_len, -1)\n",
        "\n",
        "        # shape: output [bsz,seq_len,dim]\n",
        "        return self.wo(output)\n",
        "\n",
        "# If the number of keys/values heads is less than query heads, this function expands the key/values embeddings with the required number of repetition\n",
        "def repeat_kv(x:torch.Tensor, n_rep: int)-> torch.Tensor:\n",
        "  bsz, seq_len, n_kv_heads, head_dim = x.shape\n",
        "  if n_rep == 1:\n",
        "    return x\n",
        "  return (\n",
        "      x[:,:,:,None,:]\n",
        "      .expand(bsz,seq_len,n_kv_heads,n_rep, head_dim)\n",
        "      .reshape(bsz,seq_len,n_kv_heads * n_rep, head_dim))\n",
        "\n",
        "\n",
        "### Test: Repeat_kv function ##\n",
        "\n",
        "n_rep = ModelArgs.n_heads // ModelArgs.n_kv_heads\n",
        "keys = repeat_kv(xk, n_rep)\n",
        "print(f\"xk.shape: {xk.shape}\")\n",
        "print(f\"keys.shape: {keys.shape}\")\n",
        "\n",
        "attention = Attention(ModelArgs)\n",
        "x_out = attention(x_norm,start_pos=0, inference=False)\n",
        "print(f\"x_out.shape: {x_out.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KuwGFQwUs50",
        "outputId": "f7327607-41e6-4ea9-eb07-70173ff38be7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xk.shape: torch.Size([10, 256, 4, 64])\n",
            "keys.shape: torch.Size([10, 256, 8, 64])\n",
            "x_out.shape: torch.Size([10, 256, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feed forward network with SwiGLU activation"
      ],
      "metadata": {
        "id": "vOmKtuNQYI5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim:int, hidden_dim:int, multiple_of:int, ffn_dim_multiplier: Optional[float]):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        hidden_dim = int(2*hidden_dim/3)\n",
        "        if ffn_dim_multiplier is not None:\n",
        "            hidden_dim = int(ffn_dim_multiplier * hidden_dim)\n",
        "\n",
        "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
        "\n",
        "        self.w1 = nn.Linear(self.dim, hidden_dim, bias=False, device=device)\n",
        "        self.w2 = nn.Linear(hidden_dim, self.dim, bias=False, device=device)\n",
        "        self.w3 = nn.Linear(self.dim, hidden_dim, bias=False, device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
        "\n",
        "feed_forward = FeedForward(ModelArgs.dim, 4 * ModelArgs.dim, ModelArgs.multiple_of, ModelArgs.ffn_dim_multiplier)\n",
        "x_out = rms_norm(x_out)\n",
        "x_out = feed_forward(x_out)\n",
        "print(f\"feed forward output: x_out.shape: {x_out.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQhNtxq2X2Of",
        "outputId": "47c09291-7d52-4070-d097-cb4b9b7b38cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feed forward output: x_out.shape: torch.Size([10, 256, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder Block"
      ],
      "metadata": {
        "id": "b5zC6QyiZMvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, args: ModelArgs):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.attention_norm = RMSNorm(dim=args.dim, eps = args.norm_eps)\n",
        "        self.attention = Attention(args)\n",
        "        self.ff_norm = RMSNorm(dim=args.dim, eps=args.norm_eps)\n",
        "        self.feedforward = FeedForward(args.dim, 4*args.dim,args.multiple_of, args.ffn_dim_multiplier)\n",
        "\n",
        "    def forward(self, x, start_pos, inference):\n",
        "        h = x + self.attention(self.attention_norm(x), start_pos, inference)\n",
        "        out = h + self.feedforward(self.ff_norm(h))\n",
        "        return out\n",
        "\n",
        "x = torch.randn((ModelArgs.max_batch_size, ModelArgs.max_seq_len, ModelArgs.dim), device=device)\n",
        "transformer_block = TransformerBlock(ModelArgs)\n",
        "transformer_block_out = transformer_block(x,start_pos=0, inference=False)\n",
        "print(f\"transformer_block_out.shape: {transformer_block_out.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PlcOnM0Y-Vx",
        "outputId": "988bafbb-43be-4a53-bded-b0bfee5071a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer_block_out.shape: torch.Size([10, 256, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMA3 Model put together"
      ],
      "metadata": {
        "id": "3XBGLcMPavFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, params: ModelArgs):\n",
        "    super().__init__()\n",
        "    self.params = params\n",
        "    self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
        "\n",
        "    self.layers = nn.ModuleList()\n",
        "    for layer_id in range(params.n_layers):\n",
        "      self.layers.append(TransformerBlock(args=params))\n",
        "\n",
        "    self.norm = RMSNorm(params.dim, eps = params.norm_eps)\n",
        "\n",
        "    self.output = nn.Linear(params.dim, params.vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x, start_pos=0, targets=None):\n",
        "    h = self.tok_embeddings(x)\n",
        "\n",
        "    if targets is None:\n",
        "      inference = True\n",
        "    else:\n",
        "      inference = False\n",
        "\n",
        "    for layer in self.layers:\n",
        "      h = layer(h, start_pos, inference)\n",
        "\n",
        "    h = self.norm(h)\n",
        "\n",
        "    logits = self.output(h).float()\n",
        "    loss = None\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      loss = F.cross_entropy(logits.view(-1, self.params.vocab_size), targets.view(-1))\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "\n",
        "### Test: Transformer (Llama Model) ###\n",
        "\n",
        "model = Transformer(ModelArgs).to(ModelArgs.device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24BbWBjvad8a",
        "outputId": "14642ffc-9dbc-4e72-81a8-24c1ed5c2cfe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (tok_embeddings): Embedding(68, 512)\n",
            "  (layers): ModuleList(\n",
            "    (0-7): 8 x TransformerBlock(\n",
            "      (attention_norm): RMSNorm()\n",
            "      (attention): Attention(\n",
            "        (wq): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (wk): Linear(in_features=512, out_features=256, bias=False)\n",
            "        (wv): Linear(in_features=512, out_features=256, bias=False)\n",
            "        (wo): Linear(in_features=512, out_features=512, bias=False)\n",
            "      )\n",
            "      (ff_norm): RMSNorm()\n",
            "      (feedforward): FeedForward(\n",
            "        (w1): Linear(in_features=512, out_features=1536, bias=False)\n",
            "        (w2): Linear(in_features=1536, out_features=512, bias=False)\n",
            "        (w3): Linear(in_features=512, out_features=1536, bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): RMSNorm()\n",
            "  (output): Linear(in_features=512, out_features=68, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "WRscpzHRbDLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.tensor(encode(data), dtype=torch.int).to(ModelArgs.device)\n",
        "print(f\"dataset-shape: {dataset.shape}\")\n",
        "\n",
        "# Define function to generate batches from the given dataset\n",
        "def get_dataset_batch(data, split, args:ModelArgs):\n",
        "  seq_len = args.max_seq_len\n",
        "  batch_size = args.max_batch_size\n",
        "  device = args.device\n",
        "\n",
        "  train = data[:int(0.8 * len(data))]\n",
        "  val = data[int(0.8 * len(data)): int(0.9 * len(data))]\n",
        "  test = data[int(0.9 * len(data)):]\n",
        "\n",
        "  batch_data = train\n",
        "  if split == \"val\":\n",
        "    batch_data = val\n",
        "\n",
        "  if split == \"test\":\n",
        "    batch_data = test\n",
        "\n",
        "  # Picking random starting points from the dataset to give random samples for training, validation and testing.\n",
        "  ix = torch.randint(0, len(batch_data) - seq_len - 3, (batch_size,)).to(device)\n",
        "  x = torch.stack([torch.cat([token_bos, batch_data[i:i+seq_len-1]]) for i in ix]).long().to(device)\n",
        "  y = torch.stack([torch.cat([batch_data[i+1:i+seq_len], token_eos]) for i in ix]).long().to(device)\n",
        "\n",
        "  return x,y\n",
        "\n",
        "### Test: get_dataset function ###\n",
        "xs, ys = get_dataset_batch(dataset, split=\"train\", args=ModelArgs)\n",
        "print([(decode(xs[i].tolist()), decode(ys[i].tolist())) for i in range(len(xs))])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_loss(model, args:ModelArgs):\n",
        "  out = {}\n",
        "  model.eval()\n",
        "\n",
        "  for split in [\"train\", \"val\"]:\n",
        "    losses = []\n",
        "    for _ in range(10):\n",
        "      xb, yb = get_dataset_batch(dataset, split, args)\n",
        "      _, loss = model(x=xb, targets=yb)\n",
        "      losses.append(loss.item())\n",
        "    out[split] = np.mean(losses)\n",
        "\n",
        "  model.train()\n",
        "  return out\n",
        "\n",
        "def train(model, optimizer, args:ModelArgs):\n",
        "    epochs = args.epochs\n",
        "    log_interval = args.log_interval\n",
        "    device = args.device\n",
        "    losses = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        xs, ys = get_dataset_batch(dataset, 'train', args)\n",
        "        xs = xs.to(device)\n",
        "        ys = ys.to(device)\n",
        "        logits, loss = model(x=xs, targets=ys)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % log_interval == 0:\n",
        "            batch_time = time.time() - start_time\n",
        "            x = evaluate_loss(model, args)\n",
        "            losses += [x]\n",
        "            print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f}\")\n",
        "            start_time = time.time()\n",
        "\n",
        "    # Print the final validation loss\n",
        "    print(\"validation loss: \", losses[-1]['val'])\n",
        "    return pd.DataFrame(losses).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKO5np8Va8yd",
        "outputId": "f93c29e7-8bba-4022-b638-4228912c2588"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset-shape: torch.Size([1115394])\n",
            "[(\"<|begin_of_text|>Warwick, single out some other chase;\\nFor I myself will hunt this wolf to death.\\n3 KING HENRY VI\\n\\nKING HENRY VI:\\nThis battle fares like to the morning's war,\\nWhen dying clouds contend with growing light,\\nWhat time the shepherd, blowing of his nails,\\nCan n\", \"arwick, single out some other chase;\\nFor I myself will hunt this wolf to death.\\n3 KING HENRY VI\\n\\nKING HENRY VI:\\nThis battle fares like to the morning's war,\\nWhen dying clouds contend with growing light,\\nWhat time the shepherd, blowing of his nails,\\nCan ne<|end_of_text|>\"), ('<|begin_of_text|>ein Clarence shall not want his part.\\n\\nKING HENRY VI:\\nBut, with the first of all your chief affairs,\\nLet me entreat, for I command no more,\\nThat Margaret your queen and my son Edward\\nBe sent for, to return from France with speed;\\nFor, till I see them here', 'in Clarence shall not want his part.\\n\\nKING HENRY VI:\\nBut, with the first of all your chief affairs,\\nLet me entreat, for I command no more,\\nThat Margaret your queen and my son Edward\\nBe sent for, to return from France with speed;\\nFor, till I see them here,<|end_of_text|>'), (\"<|begin_of_text|>our.\\n\\nESCALUS:\\nHe's in the right. Constable, what say you to it?\\n\\nELBOW:\\nFirst, an it like you, the house is a respected\\nhouse; next, this is a respected fellow; and his\\nmistress is a respected woman.\\n\\nPOMPEY:\\nBy this hand, sir, his wife is a more respect\", \"ur.\\n\\nESCALUS:\\nHe's in the right. Constable, what say you to it?\\n\\nELBOW:\\nFirst, an it like you, the house is a respected\\nhouse; next, this is a respected fellow; and his\\nmistress is a respected woman.\\n\\nPOMPEY:\\nBy this hand, sir, his wife is a more respecte<|end_of_text|>\"), (\"<|begin_of_text|>d\\nBy thinking on the frosty Caucasus?\\nOr cloy the hungry edge of appetite\\nBy bare imagination of a feast?\\nOr wallow naked in December snow\\nBy thinking on fantastic summer's heat?\\nO, no! the apprehension of the good\\nGives but the greater feeling to the wor\", \"\\nBy thinking on the frosty Caucasus?\\nOr cloy the hungry edge of appetite\\nBy bare imagination of a feast?\\nOr wallow naked in December snow\\nBy thinking on fantastic summer's heat?\\nO, no! the apprehension of the good\\nGives but the greater feeling to the wors<|end_of_text|>\"), ('<|begin_of_text|>incur the last,\\nDefinitively thus I answer you.\\nYour love deserves my thanks; but my desert\\nUnmeritable shuns your high request.\\nFirst if all obstacles were cut away,\\nAnd that my path were even to the crown,\\nAs my ripe revenue and due by birth\\nYet so much', 'ncur the last,\\nDefinitively thus I answer you.\\nYour love deserves my thanks; but my desert\\nUnmeritable shuns your high request.\\nFirst if all obstacles were cut away,\\nAnd that my path were even to the crown,\\nAs my ripe revenue and due by birth\\nYet so much <|end_of_text|>'), (\"<|begin_of_text|>d man,\\nWhom with a crack'd heart I have sent to Rome,\\nLoved me above the measure of a father;\\nNay, godded me, indeed. Their latest refuge\\nWas to send him; for whose old love I have,\\nThough I show'd sourly to him, once more offer'd\\nThe first conditions, wh\", \" man,\\nWhom with a crack'd heart I have sent to Rome,\\nLoved me above the measure of a father;\\nNay, godded me, indeed. Their latest refuge\\nWas to send him; for whose old love I have,\\nThough I show'd sourly to him, once more offer'd\\nThe first conditions, whi<|end_of_text|>\"), (\"<|begin_of_text|>see that day.\\n\\nLORD FITZWATER:\\nNow by my soul, I would it were this hour.\\n\\nDUKE OF AUMERLE:\\nFitzwater, thou art damn'd to hell for this.\\n\\nHENRY PERCY:\\nAumerle, thou liest; his honour is as true\\nIn this appeal as thou art all unjust;\\nAnd that thou art so, \", \"ee that day.\\n\\nLORD FITZWATER:\\nNow by my soul, I would it were this hour.\\n\\nDUKE OF AUMERLE:\\nFitzwater, thou art damn'd to hell for this.\\n\\nHENRY PERCY:\\nAumerle, thou liest; his honour is as true\\nIn this appeal as thou art all unjust;\\nAnd that thou art so, t<|end_of_text|>\"), (\"<|begin_of_text|>\\nBut where to-morrow?  Well, all's one for that.\\nWho hath descried the number of the foe?\\n\\nNORFOLK:\\nSix or seven thousand is their utmost power.\\n\\nKING RICHARD III:\\nWhy, our battalion trebles that account:\\nBesides, the king's name is a tower of strength,\\nW\", \"But where to-morrow?  Well, all's one for that.\\nWho hath descried the number of the foe?\\n\\nNORFOLK:\\nSix or seven thousand is their utmost power.\\n\\nKING RICHARD III:\\nWhy, our battalion trebles that account:\\nBesides, the king's name is a tower of strength,\\nWh<|end_of_text|>\"), ('<|begin_of_text|>o.\\n\\nPETER:\\nI will then give it you soundly.\\n\\nFirst Musician:\\nWhat will you give us?\\n\\nPETER:\\nNo money, on my faith, but the gleek;\\nI will give you the minstrel.\\n\\nFirst Musician:\\nThen I will give you the serving-creature.\\n\\nPETER:\\nThen will I lay the serving', '.\\n\\nPETER:\\nI will then give it you soundly.\\n\\nFirst Musician:\\nWhat will you give us?\\n\\nPETER:\\nNo money, on my faith, but the gleek;\\nI will give you the minstrel.\\n\\nFirst Musician:\\nThen I will give you the serving-creature.\\n\\nPETER:\\nThen will I lay the serving-<|end_of_text|>'), (\"<|begin_of_text|>our quondam queen,\\nYou have a father able to maintain you;\\nAnd better 'twere you troubled him than France.\\n\\nQUEEN MARGARET:\\nPeace, impudent and shameless Warwick, peace,\\nProud setter up and puller down of kings!\\nI will not hence, till, with my talk and te\", \"ur quondam queen,\\nYou have a father able to maintain you;\\nAnd better 'twere you troubled him than France.\\n\\nQUEEN MARGARET:\\nPeace, impudent and shameless Warwick, peace,\\nProud setter up and puller down of kings!\\nI will not hence, till, with my talk and tea<|end_of_text|>\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(ModelArgs).to(ModelArgs.device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train(model, optimizer, ModelArgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0gRQ4w6FbMk_",
        "outputId": "6b2638d7-9275-4133-c9ba-b47c201956ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | val loss 3.802 | Time 1.069\n",
            "Epoch 10 | val loss 3.042 | Time 1.313\n",
            "Epoch 20 | val loss 2.970 | Time 1.456\n",
            "Epoch 30 | val loss 2.957 | Time 1.295\n",
            "Epoch 40 | val loss 2.945 | Time 1.301\n",
            "Epoch 50 | val loss 2.897 | Time 1.305\n",
            "Epoch 60 | val loss 2.872 | Time 1.324\n",
            "Epoch 70 | val loss 2.852 | Time 1.303\n",
            "Epoch 80 | val loss 2.810 | Time 1.300\n",
            "Epoch 90 | val loss 2.819 | Time 1.300\n",
            "Epoch 100 | val loss 2.799 | Time 1.312\n",
            "Epoch 110 | val loss 2.787 | Time 1.315\n",
            "Epoch 120 | val loss 2.758 | Time 1.320\n",
            "Epoch 130 | val loss 2.729 | Time 1.306\n",
            "Epoch 140 | val loss 2.720 | Time 1.313\n",
            "Epoch 150 | val loss 2.675 | Time 1.314\n",
            "Epoch 160 | val loss 2.680 | Time 1.320\n",
            "Epoch 170 | val loss 2.643 | Time 1.343\n",
            "Epoch 180 | val loss 2.651 | Time 1.318\n",
            "Epoch 190 | val loss 2.615 | Time 1.329\n",
            "Epoch 200 | val loss 2.643 | Time 1.328\n",
            "Epoch 210 | val loss 2.652 | Time 1.332\n",
            "Epoch 220 | val loss 2.622 | Time 1.359\n",
            "Epoch 230 | val loss 2.593 | Time 1.360\n",
            "Epoch 240 | val loss 2.603 | Time 1.338\n",
            "Epoch 250 | val loss 2.580 | Time 1.354\n",
            "Epoch 260 | val loss 2.570 | Time 1.350\n",
            "Epoch 270 | val loss 2.581 | Time 1.370\n",
            "Epoch 280 | val loss 2.537 | Time 1.359\n",
            "Epoch 290 | val loss 2.564 | Time 1.368\n",
            "Epoch 300 | val loss 2.542 | Time 1.364\n",
            "Epoch 310 | val loss 2.523 | Time 1.407\n",
            "Epoch 320 | val loss 2.559 | Time 1.401\n",
            "Epoch 330 | val loss 2.527 | Time 1.381\n",
            "Epoch 340 | val loss 2.533 | Time 1.382\n",
            "Epoch 350 | val loss 2.477 | Time 1.368\n",
            "Epoch 360 | val loss 2.494 | Time 1.388\n",
            "Epoch 370 | val loss 2.532 | Time 1.386\n",
            "Epoch 380 | val loss 2.528 | Time 1.373\n",
            "Epoch 390 | val loss 2.497 | Time 1.377\n",
            "Epoch 400 | val loss 2.471 | Time 1.386\n",
            "Epoch 410 | val loss 2.469 | Time 1.401\n",
            "Epoch 420 | val loss 2.429 | Time 1.391\n",
            "Epoch 430 | val loss 2.434 | Time 1.397\n",
            "Epoch 440 | val loss 2.462 | Time 1.392\n",
            "Epoch 450 | val loss 2.445 | Time 1.404\n",
            "Epoch 460 | val loss 2.462 | Time 1.408\n",
            "Epoch 470 | val loss 2.462 | Time 1.410\n",
            "Epoch 480 | val loss 2.447 | Time 1.414\n",
            "Epoch 490 | val loss 2.447 | Time 1.408\n",
            "Epoch 500 | val loss 2.440 | Time 1.505\n",
            "Epoch 510 | val loss 2.440 | Time 1.439\n",
            "Epoch 520 | val loss 2.447 | Time 1.422\n",
            "Epoch 530 | val loss 2.416 | Time 1.433\n",
            "Epoch 540 | val loss 2.414 | Time 1.432\n",
            "Epoch 550 | val loss 2.407 | Time 1.483\n",
            "Epoch 560 | val loss 2.388 | Time 1.436\n",
            "Epoch 570 | val loss 2.389 | Time 1.438\n",
            "Epoch 580 | val loss 2.406 | Time 1.453\n",
            "Epoch 590 | val loss 2.406 | Time 1.496\n",
            "Epoch 600 | val loss 2.409 | Time 1.617\n",
            "Epoch 610 | val loss 2.392 | Time 1.754\n",
            "Epoch 620 | val loss 2.408 | Time 1.498\n",
            "Epoch 630 | val loss 2.390 | Time 1.475\n",
            "Epoch 640 | val loss 2.357 | Time 1.469\n",
            "Epoch 650 | val loss 2.386 | Time 1.635\n",
            "Epoch 660 | val loss 2.377 | Time 1.581\n",
            "Epoch 670 | val loss 2.403 | Time 1.452\n",
            "Epoch 680 | val loss 2.361 | Time 1.470\n",
            "Epoch 690 | val loss 2.414 | Time 1.475\n",
            "Epoch 700 | val loss 2.403 | Time 1.532\n",
            "Epoch 710 | val loss 2.371 | Time 1.468\n",
            "Epoch 720 | val loss 2.348 | Time 1.480\n",
            "Epoch 730 | val loss 2.363 | Time 1.480\n",
            "Epoch 740 | val loss 2.364 | Time 1.567\n",
            "Epoch 750 | val loss 2.355 | Time 1.488\n",
            "Epoch 760 | val loss 2.366 | Time 1.477\n",
            "Epoch 770 | val loss 2.358 | Time 1.488\n",
            "Epoch 780 | val loss 2.337 | Time 1.497\n",
            "Epoch 790 | val loss 2.359 | Time 1.493\n",
            "Epoch 800 | val loss 2.340 | Time 1.493\n",
            "Epoch 810 | val loss 2.330 | Time 1.497\n",
            "Epoch 820 | val loss 2.339 | Time 1.497\n",
            "Epoch 830 | val loss 2.359 | Time 1.500\n",
            "Epoch 840 | val loss 2.335 | Time 1.491\n",
            "Epoch 850 | val loss 2.319 | Time 1.507\n",
            "Epoch 860 | val loss 2.312 | Time 1.466\n",
            "Epoch 870 | val loss 2.318 | Time 1.486\n",
            "Epoch 880 | val loss 2.364 | Time 1.475\n",
            "Epoch 890 | val loss 2.315 | Time 1.478\n",
            "Epoch 900 | val loss 2.301 | Time 1.484\n",
            "Epoch 910 | val loss 2.268 | Time 1.478\n",
            "Epoch 920 | val loss 2.312 | Time 1.702\n",
            "Epoch 930 | val loss 2.330 | Time 1.504\n",
            "Epoch 940 | val loss 2.318 | Time 1.482\n",
            "Epoch 950 | val loss 2.293 | Time 1.487\n",
            "Epoch 960 | val loss 2.336 | Time 1.518\n",
            "Epoch 970 | val loss 2.323 | Time 1.488\n",
            "Epoch 980 | val loss 2.322 | Time 1.509\n",
            "Epoch 990 | val loss 2.322 | Time 1.502\n",
            "Epoch 1000 | val loss 2.314 | Time 1.493\n",
            "Epoch 1010 | val loss 2.300 | Time 1.522\n",
            "Epoch 1020 | val loss 2.336 | Time 1.503\n",
            "Epoch 1030 | val loss 2.310 | Time 1.502\n",
            "Epoch 1040 | val loss 2.267 | Time 1.502\n",
            "Epoch 1050 | val loss 2.303 | Time 1.509\n",
            "Epoch 1060 | val loss 2.269 | Time 1.507\n",
            "Epoch 1070 | val loss 2.270 | Time 1.506\n",
            "Epoch 1080 | val loss 2.243 | Time 1.506\n",
            "Epoch 1090 | val loss 2.296 | Time 1.489\n",
            "Epoch 1100 | val loss 2.257 | Time 1.506\n",
            "Epoch 1110 | val loss 2.283 | Time 1.500\n",
            "Epoch 1120 | val loss 2.288 | Time 1.497\n",
            "Epoch 1130 | val loss 2.260 | Time 1.508\n",
            "Epoch 1140 | val loss 2.269 | Time 1.516\n",
            "Epoch 1150 | val loss 2.266 | Time 1.503\n",
            "Epoch 1160 | val loss 2.296 | Time 1.509\n",
            "Epoch 1170 | val loss 2.252 | Time 1.517\n",
            "Epoch 1180 | val loss 2.269 | Time 1.519\n",
            "Epoch 1190 | val loss 2.229 | Time 1.507\n",
            "Epoch 1200 | val loss 2.259 | Time 1.516\n",
            "Epoch 1210 | val loss 2.229 | Time 1.504\n",
            "Epoch 1220 | val loss 2.216 | Time 1.514\n",
            "Epoch 1230 | val loss 2.234 | Time 1.535\n",
            "Epoch 1240 | val loss 2.277 | Time 1.519\n",
            "Epoch 1250 | val loss 2.218 | Time 1.522\n",
            "Epoch 1260 | val loss 2.291 | Time 1.516\n",
            "Epoch 1270 | val loss 2.242 | Time 1.551\n",
            "Epoch 1280 | val loss 2.266 | Time 1.523\n",
            "Epoch 1290 | val loss 2.255 | Time 1.532\n",
            "Epoch 1300 | val loss 2.231 | Time 1.527\n",
            "Epoch 1310 | val loss 2.246 | Time 1.553\n",
            "Epoch 1320 | val loss 2.238 | Time 1.535\n",
            "Epoch 1330 | val loss 2.222 | Time 1.536\n",
            "Epoch 1340 | val loss 2.239 | Time 1.533\n",
            "Epoch 1350 | val loss 2.277 | Time 1.543\n",
            "Epoch 1360 | val loss 2.255 | Time 1.536\n",
            "Epoch 1370 | val loss 2.238 | Time 1.536\n",
            "Epoch 1380 | val loss 2.249 | Time 1.531\n",
            "Epoch 1390 | val loss 2.239 | Time 1.539\n",
            "Epoch 1400 | val loss 2.242 | Time 1.552\n",
            "Epoch 1410 | val loss 2.246 | Time 1.535\n",
            "Epoch 1420 | val loss 2.208 | Time 1.535\n",
            "Epoch 1430 | val loss 2.231 | Time 1.535\n",
            "Epoch 1440 | val loss 2.255 | Time 1.541\n",
            "Epoch 1450 | val loss 2.261 | Time 1.536\n",
            "Epoch 1460 | val loss 2.247 | Time 1.537\n",
            "Epoch 1470 | val loss 2.235 | Time 1.535\n",
            "Epoch 1480 | val loss 2.221 | Time 1.534\n",
            "Epoch 1490 | val loss 2.208 | Time 1.543\n",
            "Epoch 1500 | val loss 2.209 | Time 1.536\n",
            "Epoch 1510 | val loss 2.242 | Time 1.536\n",
            "Epoch 1520 | val loss 2.220 | Time 1.532\n",
            "Epoch 1530 | val loss 2.234 | Time 1.560\n",
            "Epoch 1540 | val loss 2.266 | Time 1.541\n",
            "Epoch 1550 | val loss 2.230 | Time 1.539\n",
            "Epoch 1560 | val loss 2.219 | Time 1.537\n",
            "Epoch 1570 | val loss 2.224 | Time 1.553\n",
            "Epoch 1580 | val loss 2.266 | Time 1.547\n",
            "Epoch 1590 | val loss 2.254 | Time 1.546\n",
            "Epoch 1600 | val loss 2.215 | Time 1.544\n",
            "Epoch 1610 | val loss 2.239 | Time 1.566\n",
            "Epoch 1620 | val loss 2.253 | Time 1.546\n",
            "Epoch 1630 | val loss 2.246 | Time 1.551\n",
            "Epoch 1640 | val loss 2.225 | Time 1.546\n",
            "Epoch 1650 | val loss 2.220 | Time 1.555\n",
            "Epoch 1660 | val loss 2.249 | Time 1.557\n",
            "Epoch 1670 | val loss 2.235 | Time 1.557\n",
            "Epoch 1680 | val loss 2.152 | Time 1.556\n",
            "Epoch 1690 | val loss 2.153 | Time 1.564\n",
            "Epoch 1700 | val loss 2.218 | Time 1.575\n",
            "Epoch 1710 | val loss 2.211 | Time 1.563\n",
            "Epoch 1720 | val loss 2.183 | Time 1.555\n",
            "Epoch 1730 | val loss 2.186 | Time 1.556\n",
            "Epoch 1740 | val loss 2.215 | Time 1.563\n",
            "Epoch 1750 | val loss 2.200 | Time 1.558\n",
            "Epoch 1760 | val loss 2.228 | Time 1.556\n",
            "Epoch 1770 | val loss 2.207 | Time 1.557\n",
            "Epoch 1780 | val loss 2.171 | Time 1.567\n",
            "Epoch 1790 | val loss 2.241 | Time 1.558\n",
            "Epoch 1800 | val loss 2.177 | Time 1.555\n",
            "Epoch 1810 | val loss 2.234 | Time 1.558\n",
            "Epoch 1820 | val loss 2.197 | Time 1.558\n",
            "Epoch 1830 | val loss 2.225 | Time 1.548\n",
            "Epoch 1840 | val loss 2.181 | Time 1.562\n",
            "Epoch 1850 | val loss 2.219 | Time 1.556\n",
            "Epoch 1860 | val loss 2.187 | Time 1.555\n",
            "Epoch 1870 | val loss 2.150 | Time 1.571\n",
            "Epoch 1880 | val loss 2.202 | Time 1.557\n",
            "Epoch 1890 | val loss 2.192 | Time 1.551\n",
            "Epoch 1900 | val loss 2.182 | Time 1.555\n",
            "Epoch 1910 | val loss 2.200 | Time 1.561\n",
            "Epoch 1920 | val loss 2.144 | Time 1.555\n",
            "Epoch 1930 | val loss 2.240 | Time 1.552\n",
            "Epoch 1940 | val loss 2.194 | Time 1.549\n",
            "Epoch 1950 | val loss 2.193 | Time 1.569\n",
            "Epoch 1960 | val loss 2.189 | Time 1.553\n",
            "Epoch 1970 | val loss 2.171 | Time 1.555\n",
            "Epoch 1980 | val loss 2.220 | Time 1.551\n",
            "Epoch 1990 | val loss 2.183 | Time 1.549\n",
            "Epoch 2000 | val loss 2.172 | Time 1.552\n",
            "Epoch 2010 | val loss 2.229 | Time 1.552\n",
            "Epoch 2020 | val loss 2.176 | Time 1.554\n",
            "Epoch 2030 | val loss 2.209 | Time 1.555\n",
            "Epoch 2040 | val loss 2.215 | Time 1.564\n",
            "Epoch 2050 | val loss 2.180 | Time 1.555\n",
            "Epoch 2060 | val loss 2.138 | Time 1.552\n",
            "Epoch 2070 | val loss 2.156 | Time 1.550\n",
            "Epoch 2080 | val loss 2.225 | Time 1.567\n",
            "Epoch 2090 | val loss 2.176 | Time 1.547\n",
            "Epoch 2100 | val loss 2.191 | Time 1.548\n",
            "Epoch 2110 | val loss 2.156 | Time 1.548\n",
            "Epoch 2120 | val loss 2.149 | Time 1.558\n",
            "Epoch 2130 | val loss 2.187 | Time 1.542\n",
            "Epoch 2140 | val loss 2.149 | Time 1.551\n",
            "Epoch 2150 | val loss 2.203 | Time 1.554\n",
            "Epoch 2160 | val loss 2.200 | Time 1.547\n",
            "Epoch 2170 | val loss 2.164 | Time 1.547\n",
            "Epoch 2180 | val loss 2.205 | Time 1.547\n",
            "Epoch 2190 | val loss 2.193 | Time 1.550\n",
            "Epoch 2200 | val loss 2.183 | Time 1.548\n",
            "Epoch 2210 | val loss 2.169 | Time 1.558\n",
            "Epoch 2220 | val loss 2.152 | Time 1.546\n",
            "Epoch 2230 | val loss 2.263 | Time 1.549\n",
            "Epoch 2240 | val loss 2.166 | Time 1.548\n",
            "Epoch 2250 | val loss 2.183 | Time 1.562\n",
            "Epoch 2260 | val loss 2.198 | Time 1.550\n",
            "Epoch 2270 | val loss 2.211 | Time 1.550\n",
            "Epoch 2280 | val loss 2.197 | Time 1.545\n",
            "Epoch 2290 | val loss 2.182 | Time 1.557\n",
            "Epoch 2300 | val loss 2.206 | Time 1.548\n",
            "Epoch 2310 | val loss 2.202 | Time 1.547\n",
            "Epoch 2320 | val loss 2.175 | Time 1.547\n",
            "Epoch 2330 | val loss 2.199 | Time 1.547\n",
            "Epoch 2340 | val loss 2.208 | Time 1.549\n",
            "Epoch 2350 | val loss 2.196 | Time 1.546\n",
            "Epoch 2360 | val loss 2.215 | Time 1.548\n",
            "Epoch 2370 | val loss 2.189 | Time 1.556\n",
            "Epoch 2380 | val loss 2.173 | Time 1.562\n",
            "Epoch 2390 | val loss 2.199 | Time 1.551\n",
            "Epoch 2400 | val loss 2.184 | Time 1.546\n",
            "Epoch 2410 | val loss 2.173 | Time 1.536\n",
            "Epoch 2420 | val loss 2.196 | Time 1.567\n",
            "Epoch 2430 | val loss 2.219 | Time 1.549\n",
            "Epoch 2440 | val loss 2.226 | Time 1.546\n",
            "Epoch 2450 | val loss 2.185 | Time 1.546\n",
            "Epoch 2460 | val loss 2.172 | Time 1.562\n",
            "Epoch 2470 | val loss 2.236 | Time 1.550\n",
            "Epoch 2480 | val loss 2.229 | Time 1.549\n",
            "Epoch 2490 | val loss 2.181 | Time 1.548\n",
            "validation loss:  2.180785346031189\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACHNElEQVR4nO3dd3hU1dbA4d/MpPeEkEYSSCB0QgcDCAihiQqCKIoiimIBr+i14bWXC5bPa7kKduQqoiigooC0UEPvndBCQkIgkN4z5/tjT8mQhCQQMgHW+zzzzMyZc87sc0Rmsffaa+s0TdMQQgghhKjH9PZugBBCCCFEVSRgEUIIIUS9JwGLEEIIIeo9CViEEEIIUe9JwCKEEEKIek8CFiGEEELUexKwCCGEEKLek4BFCCGEEPWeg70bUBuMRiOnTp3C09MTnU5n7+YIIYQQoho0TSM7O5uQkBD0+ov3oVwTAcupU6cICwuzdzOEEEIIcQlOnjxJaGjoRfe5JgIWT09PQF2wl5eXnVsjhBBCiOrIysoiLCzM8jt+MddEwGIeBvLy8pKARQghhLjKVCedQ5JuhRBCCFHvScAihBBCiHpPAhYhhBBC1HvXRA6LEEIIcaVomkZJSQmlpaX2bspVydHREYPBcNnnkYBFCCGEqERRUREpKSnk5eXZuylXLZ1OR2hoKB4eHpd1HglYhBBCiAoYjUaOHTuGwWAgJCQEJycnKU5aQ5qmcebMGZKSkoiKirqsnhYJWIQQQogKFBUVYTQaCQsLw83Nzd7NuWo1bNiQ48ePU1xcfFkBiyTdCiGEEBdRVcl4cXG11Ssl/xWEEEIIUe9JwCKEEEKIek8CFiGEEEJUqkmTJnz44Yf2boYk3QohhBDXmr59+9KhQ4daCTQ2b96Mu7v75TfqMknAchFnzp3njyWLcTA4MPbOUfZujhBCCFErNE2jtLQUB4eqw4CGDRvWQYuqJkNCF5F/9gQPHnyUYfuetHdThBBC2JmmaeQVldjloWlatds5btw4Vq1axUcffYROp0On0zFz5kx0Oh2LFi2ic+fOODs7s3btWo4cOcKwYcMIDAzEw8ODrl27smzZMpvzXTgkpNPp+Oqrr7j99ttxc3MjKiqK33//vbZuc6Wkh+UizPPFDZrRzi0RQghhb/nFpbR+ZYldvnvfG4Nwc6reT/ZHH33EoUOHaNu2LW+88QYAe/fuBeCFF17g/fffJzIyEl9fX06ePMnNN9/M22+/jbOzM7NmzeLWW2/l4MGDhIeHV/odr7/+Ou+++y7vvfcen3zyCWPGjOHEiRP4+fld/sVWQnpYLkKndwRAjwQsQgghrg7e3t44OTnh5uZGUFAQQUFBln+Av/HGGwwYMICmTZvi5+dH+/bteeSRR2jbti1RUVG8+eabNG3atMoek3HjxnH33XfTrFkz/v3vf5OTk8OmTZuu6HVJD8tFGBzUf2AHZMErIYS43rk6Gtj3xiC7fXdt6NKli837nJwcXnvtNf78809SUlIoKSkhPz+fxMTEi54nOjra8trd3R0vLy/S0tJqpY2VkYDlIgx6dXukh0UIIYROp6v2sEx9deFsn2eeeYalS5fy/vvv06xZM1xdXbnjjjsoKiq66HkcHR1t3ut0OozGK/tbeXXf+StMb8qedtAZ0YxGdFKeWQghxFXAycmJ0tKqRwfWrVvHuHHjuP322wHV43L8+PEr3LpLU6Nf4OnTpxMdHY2XlxdeXl7ExMSwaNGiSvfv27evJUO57GPo0KGWfcaNG1fu88GDB1/6FdUig8Eaz1XnP7wQQghRHzRp0oSNGzdy/Phxzp49W2nvR1RUFPPmzWPHjh3s3LmTe+6554r3lFyqGgUsoaGhTJs2ja1bt7Jlyxb69evHsGHDLNnHF5o3bx4pKSmWx549ezAYDIwaZVvTZPDgwTb7/fjjj5d+RbVI72Dt8io1ltixJUIIIUT1PfPMMxgMBlq3bk3Dhg0rzUn54IMP8PX1pUePHtx6660MGjSITp061XFrq6dGQ0K33nqrzfu3336b6dOns2HDBtq0aVNu/wunN82ZMwc3N7dyAYuzszNBQUE1aUqdKLsMdmlJMTi72rE1QgghRPU0b96c+Ph4m23jxo0rt1+TJk1YsWKFzbaJEyfavL9wiKiimjAZGRmX1M6auOSkjNLSUubMmUNubi4xMTHVOubrr79m9OjR5ZJ+4uLiCAgIoEWLFjz22GOkp6df9DyFhYVkZWXZPK4EQ5kelpIS6WERQggh7KXGSbe7d+8mJiaGgoICPDw8mD9/Pq1bt67yuE2bNrFnzx6+/vprm+2DBw9mxIgRREREcOTIEV588UWGDBlCfHy8TQ9HWVOnTuX111+vadNrrGwOi1YqAYsQQghhLzqtJvV+gaKiIhITE8nMzOSXX37hq6++YtWqVVUGLY888gjx8fHs2rXrovsdPXqUpk2bsmzZMvr371/hPoWFhRQWFlreZ2VlERYWRmZmJl5eXjW5nIvSjKXo3lDDWumP76dBQEitnVsIIUT9VlBQwLFjx4iIiMDFxcXezblqXew+ZmVl4e3tXa3f7xoPCTk5OdGsWTM6d+7M1KlTad++PR999NFFj8nNzWXOnDmMHz++yvNHRkbi7+9PQkJCpfs4OztbZiqZH1eCTm/t4ZEeFiGEEMJ+LruwiNFotOntqMjcuXMpLCzk3nvvrfJ8SUlJpKenExwcfLlNqxXFmgpaSiRgEUIIIeymRjksU6ZMYciQIYSHh5Odnc3s2bOJi4tjyRK1GNTYsWNp1KgRU6dOtTnu66+/Zvjw4TRo0MBme05ODq+//jojR44kKCiII0eO8Nxzz9GsWTMGDbJP+eMLGdEDpRhLiu3dFCGEEOK6VaOAJS0tjbFjx5KSkoK3tzfR0dEsWbKEAQMGAJCYmIj+gmqwBw8eZO3atfz999/lzmcwGNi1axffffcdGRkZhISEMHDgQN58802cnZ0v47JqT6mpE8ooheOEEEIIu6lRwHLhDJ8LxcXFldvWokWLCudsA7i6ulp6Z+qrUp0pYDFKD4sQQghhL7I4ThWMqBwW6WERQghxvWjSpAkffvihvZthQwKWKpiHhEqlcJwQQghhNxKwVMFoukWarCUkhBBC2I0ELFUoNQ0JyWrNQgghrgZffPEFISEh5VZdHjZsGA8++CBHjhxh2LBhBAYG4uHhQdeuXVm2bJmdWlt9ErBUwWhOui2VpFshhLiuaRoU5drnUYOi9KNGjSI9PZ2VK1datp07d47FixczZswYcnJyuPnmm1m+fDnbt29n8ODB3HrrrZWu6Fxf1HgtoeuNOelWkx4WIYS4vhXnwb/ttETLi6fAyb3q/QBfX1+GDBnC7NmzLUvc/PLLL/j7+3PTTTeh1+tp3769Zf8333yT+fPn8/vvvzNp0qQr0vzaID0sVTDqzLOEJIdFCCHE1WHMmDH8+uuvlkr0P/zwA6NHj0av15OTk8MzzzxDq1at8PHxwcPDg/3790sPy9XOknQrAYsQQlzfHN1UT4e9vrsGbr31VjRN488//6Rr166sWbOG//znPwA888wzLF26lPfff59mzZrh6urKHXfcQVFR0ZVoea2RgKUK5h4WmSUkhBDXOZ2u2sMy9ubi4sKIESP44YcfSEhIoEWLFnTq1AmAdevWMW7cOG6//XZALZNz/PhxO7a2eiRgqYJmLs0vAYsQQoiryJgxY7jlllvYu3evzeLDUVFRzJs3j1tvvRWdTsfLL79cbkZRfSQ5LFUo1UmlWyGEEFeffv364efnx8GDB7nnnnss2z/44AN8fX3p0aMHt956K4MGDbL0vtRn0sNSBc00rRnpYRFCCHEV0ev1nDpVPuemSZMmrFixwmbbxIkTbd7XxyEi6WGpgnUtIQlYhBBCCHuRgKUKmiTdCiGEEHYnAUsVLLOEJIdFCCGEsBsJWKpgzmGRHhYhhBDCfiRgqYJ5SAij9LAIIYQQ9iIBSxUkh0UIIa5vWg0WHhTl1db9k4ClCtaARXpYhBDieuLo6AhAXl6enVtydTOX/DcYDJd1HqnDUgVJuhVCiOuTwWDAx8eHtLQ0ANzc3NDpdHZu1dXFaDRy5swZ3NzccHC4vJBDApaqmAIWnSZDQkIIcb0JCgoCsAQtoub0ej3h4eGXHexJwFIFGRISQojrl06nIzg4mICAAIqLi+3dnKuSk5MTev3lZ6BIwFIFTS+zhIQQ4npnMBguOwdDXB5Juq2C9LAIIYQQ9icBS1UsdVgkh0UIIYSwFwlYqiJDQkIIIYTdScBSBU1mCQkhhBB2JwFLVfTmHBajnRsihBBCXL8kYKmCplcTqXSSwyKEEELYjQQsVTGt1owmOSxCCCGEvUjAUhVTD4sk3QohhBD2IwFLVSxJtxKwCCGEEPYiAUtVzD0sErAIIYQQdlOjgGX69OlER0fj5eWFl5cXMTExLFq0qNL9Z86ciU6ns3m4uLjY7KNpGq+88grBwcG4uroSGxvL4cOHL+1qrgTTLCGdDAkJIYQQdlOjgCU0NJRp06axdetWtmzZQr9+/Rg2bBh79+6t9BgvLy9SUlIsjxMnTth8/u677/Lxxx8zY8YMNm7ciLu7O4MGDaKgoODSrqiW6UwLNsmQkBBCCGE/NVr88NZbb7V5//bbbzN9+nQ2bNhAmzZtKjxGp9NZlue+kKZpfPjhh7z00ksMGzYMgFmzZhEYGMiCBQsYPXp0TZp3RWg6c9KtTGsWQggh7OWSc1hKS0uZM2cOubm5xMTEVLpfTk4OjRs3JiwsrFxvzLFjx0hNTSU2Ntayzdvbm+7duxMfH1/pOQsLC8nKyrJ5XCk60+qcOqRwnBBCCGEvNQ5Ydu/ejYeHB87Ozjz66KPMnz+f1q1bV7hvixYt+Oabb/jtt9/4/vvvMRqN9OjRg6SkJABSU1MBCAwMtDkuMDDQ8llFpk6dire3t+URFhZW08uoNp2lcJwMCQkhhBD2UuOApUWLFuzYsYONGzfy2GOPcf/997Nv374K942JiWHs2LF06NCBPn36MG/ePBo2bMjnn39+WY2eMmUKmZmZlsfJkycv63wXJdOahRBCCLurUQ4LgJOTE82aNQOgc+fObN68mY8++qhaQYijoyMdO3YkISEBwJLbcvr0aYKDgy37nT59mg4dOlR6HmdnZ5ydnWva9EuiM5h6WDQZEhJCCCHs5bLrsBiNRgoLC6u1b2lpKbt377YEJxEREQQFBbF8+XLLPllZWWzcuPGieTF1SWea1qyX1ZqFEEIIu6lRD8uUKVMYMmQI4eHhZGdnM3v2bOLi4liyZAkAY8eOpVGjRkydOhWAN954gxtuuIFmzZqRkZHBe++9x4kTJ3jooYcANYNo8uTJvPXWW0RFRREREcHLL79MSEgIw4cPr90rvVR66WERQggh7K1GAUtaWhpjx44lJSUFb29voqOjWbJkCQMGDAAgMTERvd7aaXP+/HkefvhhUlNT8fX1pXPnzqxfv94mSfe5554jNzeXCRMmkJGRQa9evVi8eHG5AnP2YpklJDksQgghhN3oNE3T7N2Iy5WVlYW3tzeZmZl4eXnV6rl3/vUl7Tc9w26n9rR7cXWtnlsIIYS4ntXk91vWEqqKXnpYhBBCCHuTgKUKetMsIb3ksAghhBB2IwFLFXSWgEV6WIQQQgh7kYClCjrTWkJ6JGARQggh7EUCliropYdFCCGEsDsJWKogix8KIYQQ9icBSxV0knQrhBBC2J0ELFXQmyrdGiSHRQghhLAbCViqoHeQ0vxCCCGEvUnAUgXpYRFCCCHsTwKWKuhNSbd6SboVQggh7EYCliqYk26lh0UIIYSwHwlYqmDQyywhIYQQwt4kYKmCOelWeliEEEII+5GApQp6y5CQ9LAIIYQQ9iIBSxUM5sJxErAIIYQQdiMBSxXMPSwOGNE0zc6tEUIIIa5PErBUweDgCKgellKjBCxCCCGEPUjAUgVzHRZHXSklErAIIYQQdiEBSxXMOSwARqPMFBJCCCHsQQKWKugNjpbXJSXFdmyJEEIIcf2SgKUKDg4Gy2tjSYkdWyKEEEJcvyRgqYI56RagtFQCFiGEEMIeJGCpgk5fJodFeliEEEIIu5CApSplApYS6WERQggh7EIClqrorLfIKAGLEEIIYRcSsFRFp6NEU7dJhoSEEEII+5CApRqMpl4WSboVQggh7EMClmooNd0mo1ECFiGEEMIeJGCphlJULRYZEhJCCCHsQwKWajBKD4sQQghhVxKwVIP0sAghhBD2JQFLNUgPixBCCGFfNQpYpk+fTnR0NF5eXnh5eRETE8OiRYsq3f/LL7/kxhtvxNfXF19fX2JjY9m0aZPNPuPGjUOn09k8Bg8efGlXc4UYdaYeFpklJIQQQthFjQKW0NBQpk2bxtatW9myZQv9+vVj2LBh7N27t8L94+LiuPvuu1m5ciXx8fGEhYUxcOBAkpOTbfYbPHgwKSkplsePP/546Vd0BZh7WLTSUju3RAghhLg+OVS9i9Wtt95q8/7tt99m+vTpbNiwgTZt2pTb/4cffrB5/9VXX/Hrr7+yfPlyxo4da9nu7OxMUFBQTZpSp0p1BtCkh0UIIYSwl0vOYSktLWXOnDnk5uYSExNTrWPy8vIoLi7Gz8/PZntcXBwBAQG0aNGCxx57jPT09Iuep7CwkKysLJvHlaSZc1hKi6/o9wghhBCiYjXqYQHYvXs3MTExFBQU4OHhwfz582ndunW1jn3++ecJCQkhNjbWsm3w4MGMGDGCiIgIjhw5wosvvsiQIUOIj4/HYDBUeJ6pU6fy+uuv17Tpl8xc6VYzypCQEEIIYQ86TdO0mhxQVFREYmIimZmZ/PLLL3z11VesWrWqyqBl2rRpvPvuu8TFxREdHV3pfkePHqVp06YsW7aM/v37V7hPYWEhhYWFlvdZWVmEhYWRmZmJl5dXTS6nWk68GU3j0hNs6f0tXfqNqPXzCyGEENejrKwsvL29q/X7XeMhIScnJ5o1a0bnzp2ZOnUq7du356OPPrroMe+//z7Tpk3j77//vmiwAhAZGYm/vz8JCQmV7uPs7GyZqWR+XEnmWULItGYhhBDCLmo8JHQho9Fo09txoXfffZe3336bJUuW0KVLlyrPl5SURHp6OsHBwZfbtFoj05qFEEII+6pRwDJlyhSGDBlCeHg42dnZzJ49m7i4OJYsWQLA2LFjadSoEVOnTgXgnXfe4ZVXXmH27Nk0adKE1NRUADw8PPDw8CAnJ4fXX3+dkSNHEhQUxJEjR3juuedo1qwZgwYNquVLvXTmpFvJYRFCCCHso0YBS1paGmPHjiUlJQVvb2+io6NZsmQJAwYMACAxMRG93jrKNH36dIqKirjjjjtszvPqq6/y2muvYTAY2LVrF9999x0ZGRmEhIQwcOBA3nzzTZydnWvh8mqHuYdFkx4WIYQQwi5qFLB8/fXXF/08Li7O5v3x48cvur+rq6uld6Y+08wBi/SwCCGEEHYhawlVg1ECFiGEEMKuJGCpBs1Sh0WGhIQQQgh7kIClGjSdGjmTHhYhhBDCPiRgqQZLD4sk3QohhBB2IQFLNZiTbtGkh0UIIYSwBwlYqkGTSrdCCCGEXUnAUg0yrVkIIYSwLwlYqkHTSw+LEEIIYU8SsFSHZUhIeliEEEIIe5CApRo0CViEEEIIu5KApRokh0UIIYSwLwlYqkOvCsfpZFqzEEIIYRcSsFSDuXCcJN0KIYQQ9iEBSzXo9JLDIoQQQtiTBCzVoJmGhNCkh0UIIYSwBwlYqsMyS8ho33YIIYQQ1ykJWKrDNCSkkx4WIYQQwi4kYKkOc8AiPSxCCCGEXUjAUh0687Rm6WERQggh7EECluowzxKSOixCCCGEXUjAUh2WwnEyJCSEEELYgwQs1aDTS+E4IYQQwp4kYKkGnamHRS89LEIIIYRdSMBSHZZpzZLDIoQQQtiDBCzVoDNIwCKEEELYkwQs1aCT1ZqFEEIIu5KApRqcHB0BMJZK0q0QQghhDxKwVIOXuysAxcXFdm6JEEIIcX2SgKUafNxcANXDUlAsw0JCCCFEXZOApRrcXJ0B0GMkJbPAzq0RQgghrj8SsFSDzskdAC9dHikZ+XZujRBCCHH9kYClOnybANBEd5pTErAIIYQQdU4ClurwjQBUD8v5s6l2bowQQghx/ZGApTqc3Mh2CgCg+EyCnRsjhBBCXH9qFLBMnz6d6OhovLy88PLyIiYmhkWLFl30mLlz59KyZUtcXFxo164df/31l83nmqbxyiuvEBwcjKurK7GxsRw+fLjmV3KF5Xk0BsCQcczOLRFCCCGuPzUKWEJDQ5k2bRpbt25ly5Yt9OvXj2HDhrF3794K91+/fj13330348ePZ/v27QwfPpzhw4ezZ88eyz7vvvsuH3/8MTNmzGDjxo24u7szaNAgCgrq12wco2lYyC0n0c4tEUIIIa4/Ok3TtMs5gZ+fH++99x7jx48v99ldd91Fbm4uCxcutGy74YYb6NChAzNmzEDTNEJCQvjnP//JM888A0BmZiaBgYHMnDmT0aNHV6sNWVlZeHt7k5mZiZeX1+VcTqXOLp6G/4ap/Ekvhr725xX5DiGEEOJ6UpPf70vOYSktLWXOnDnk5uYSExNT4T7x8fHExsbabBs0aBDx8fEAHDt2jNTUVJt9vL296d69u2WfihQWFpKVlWXzuNLcQ1oA0MiYQk6hlOgXQggh6lKNA5bdu3fj4eGBs7Mzjz76KPPnz6d169YV7puamkpgYKDNtsDAQFJTUy2fm7dVtk9Fpk6dire3t+URFhZW08uoMdeAKAAa605LLRYhhBCijtU4YGnRogU7duxg48aNPPbYY9x///3s27fvSrStUlOmTCEzM9PyOHny5JX/Uj+Vw+KryyEtTaY2CyGEEHWpxgGLk5MTzZo1o3PnzkydOpX27dvz0UcfVbhvUFAQp0+fttl2+vRpgoKCLJ+bt1W2T0WcnZ0tM5XMjyvOyZ3zhgYA5KYcuvLfJ4QQQgiLy67DYjQaKSwsrPCzmJgYli9fbrNt6dKllpyXiIgIgoKCbPbJyspi48aNlebF2FOGixp6Kjl7xM4tEUIIIa4vDjXZecqUKQwZMoTw8HCys7OZPXs2cXFxLFmyBICxY8fSqFEjpk6dCsCTTz5Jnz59+L//+z+GDh3KnDlz2LJlC1988QUAOp2OyZMn89ZbbxEVFUVERAQvv/wyISEhDB8+vHavtBYUejWB3B04p+20d1OEEEKI60qNApa0tDTGjh1LSkoK3t7eREdHs2TJEgYMGABAYmIier2106ZHjx7Mnj2bl156iRdffJGoqCgWLFhA27ZtLfs899xz5ObmMmHCBDIyMujVqxeLFy/GxcWlli6x9uia9oWUBfTJmAdHx0JkH3s3SQghhLguXHYdlvqgLuqwAGTkFrJ82khGGtZgdG2A/pE48Am/Yt8nhBBCXMvqpA7L9cjH3Zn/uk1kt7EJ+vx0+OleKJYpzkIIIcSVJgFLDUU1asijRU+R7+gDKTth4VP2bpIQQghxzZOApYbaNvImmYZ8E/wq6PSw80dI3VP1gUIIIYS4ZBKw1FCbEDXG9ltmU4jorTae3GjHFgkhhBDXPglYaqhNiDcACWk5FAd3VhuTttixRUIIIcS1TwKWGgr0csbfwwmjBkecW6qNyRKwCCGEEFeSBCw1pNPp6NzYF4AJK3Rq49lDkJ9hv0YJIYQQ1zgJWC7Bq7e2oWO4D4kFbpzQAtTGU9vs2yghhBDiGiYByyUI8XFl7iMxDGwdyA5jM7Uxaat9GyWEEEJcwyRguUQOBj1Pxkax3RSw5B/bYOcWCSGEENcuCVguQ5sQb7QQNVNIO7kZjKV2bpEQQghxbZKA5TL17zeAc5oHbqWZFB9cYu/mCCGEENckCVgu040tQ/hLfxMAOeu+tHNrhBBCiGuTBCyXSafTcazJKAC8k+IgM8m+DRJCCCGuQRKw1ILmrTsSX9oaPUbYNsvezRFCCCGuORKw1IIeTf35obQ/AMbNX0NRrp1bJIQQQlxbJGCpBWF+buzz6ctxYyD6vLOwSXJZhBBCiNokAUstuSEqkI9Lbldv1n0Ehdn2bZAQQghxDZGApZb0bOrPb8aeJOtDIP8cbPnG3k0SQgghrhkSsNSS9mHelGLg8+LBasPBxfZtkBBCCHENkYClljTyccXLxYFVJW3VhuQtUJxv30YJIYQQ1wgJWGqJTqejdYgXJ7RA8p0DoLQIkjbbu1lCCCHENUECllrUJsQb0JHg1l5tOL7Wru0RQgghrhUSsNSi1sFeAKw3tlIbjq+D4gLISrFjq4QQQoirnwQstah1iApYFmZEqg1Jm+CTTvBxB0jeZr+GCSGEEFc5CVhqUbMAD5wMenYXNqTUraHKY8lKhpICWPlvezdPCCGEuGpJwFKLHA16mgd5ADoOed0AgBYWAzoDJCyFpC32baAQQghxlZKApZaZ81juOn4b44qeY0H76dB+tPpw5dugaXZsnRBCCHF1koCllvVvFQhAFu7EGTuw5kgm9H4G9A5wZAWs/Y+dWyiEEEJcfSRgqWWD2gSx5aVYvr6/CwDbEs+DXyQMMuWwLH8ddv9ixxYKIYQQVx8JWK4Afw9nujTxA+B4eh5ncwqh+yMQM0ntsPgFKC2xYwuFEEKIq4sELFeIt6sjUQEeAGxPzFAbY18DN3/IPQPH4uzVNCGEEOKqIwHLFdS5sS9gGhYCMDhCm9vV611z7dQqIYQQ4upTo4Bl6tSpdO3aFU9PTwICAhg+fDgHDx686DF9+/ZFp9OVewwdOtSyz7hx48p9Pnjw4Eu7onqkU7gKWLaeOG/dGH2nej6wEIry7NAqIYQQ4upTo4Bl1apVTJw4kQ0bNrB06VKKi4sZOHAgubm5lR4zb948UlJSLI89e/ZgMBgYNWqUzX6DBw+22e/HH3+8tCuqRzo19gFgV1IGxaVGtTG0K/g0hqIcOLTIfo0TQgghriIONdl58eLFNu9nzpxJQEAAW7dupXfv3hUe4+fnZ/N+zpw5uLm5lQtYnJ2dCQoKqklz6r1Ifw+8XR3JzC9md3Km6nHR6aDdKFjzvhoWajvS3s0UQggh6r3LymHJzMwEygclF/P1118zevRo3N3dbbbHxcUREBBAixYteOyxx0hPT6/0HIWFhWRlZdk86iO9XkevKH8AluxJtX7QzhSsJSyFvHN2aJkQQghxdbnkgMVoNDJ58mR69uxJ27Ztq3XMpk2b2LNnDw899JDN9sGDBzNr1iyWL1/OO++8w6pVqxgyZAilpaUVnmfq1Kl4e3tbHmFhYZd6GVfcLe2CAfhzdwqaucptQEsIagfGEti3wH6NE0IIIa4SOk27tFrxjz32GIsWLWLt2rWEhoZW65hHHnmE+Ph4du3addH9jh49StOmTVm2bBn9+/cv93lhYSGFhYWW91lZWYSFhZGZmYmXl1fNLuQKyy8qpdObS8kvLuW3iT1pH+ajPlj3MSx9GcJ7wIOSyyKEEOL6k5WVhbe3d7V+vy+ph2XSpEksXLiQlStXVjtYyc3NZc6cOYwfP77KfSMjI/H39ychIaHCz52dnfHy8rJ51FeuTgb6twoA4K/dKdYP2o4EdJC4HjIS7dM4IYQQ4ipRo4BF0zQmTZrE/PnzWbFiBREREdU+du7cuRQWFnLvvfdWuW9SUhLp6ekEBwfXpHn11lDTsNDPW07y6coETmcVgHcjaNJL7fDHk1CYY8cWCiGEEPVbjQKWiRMn8v333zN79mw8PT1JTU0lNTWV/Px8yz5jx45lypQp5Y79+uuvGT58OA0aNLDZnpOTw7PPPsuGDRs4fvw4y5cvZ9iwYTRr1oxBgwZd4mXVL31bBNDA3YnzecW8t+QgE2ZtUR/c9CI4uqlFEb+7BYrzL34iIYQQ4jpVo4Bl+vTpZGZm0rdvX4KDgy2Pn376ybJPYmIiKSkpNscdPHiQtWvXVjgcZDAY2LVrF7fddhvNmzdn/PjxdO7cmTVr1uDs7HyJl1W/uDoZWDy5Ny8NbQXAvpQsSkqN0LgH3L8QXH3h1HbYv9DOLRVCCCHqp0tOuq1PapK0Y09Go0arVxZTWGIk7pm+NPE3Te1ePAU2fAZdH4Kh/2ffRgohhBB15Ion3YpLo9friDAFKUfPlslZCeuunk9utEOrhBBCiPpPApY61rShWsH56JkyyxmYA5bTe6Ew2w6tEkIIIeo3CVjqWGRD1cNypGzA4hUMPuGgGSFpi51aJoQQQtRfErDUMWvAcsE0ZhkWEkIIISolAUsdi/SvYEgIrAFLwjJY+x84Gle3DRNCCCHqsRqt1iwun7mH5WxOIVkFxXi5OKoPzAFL0mb1cPaG546AwdFOLRVCCCHqD+lhqWOeLo409FT1ZWx6WQLbqDwWAJ0eCjPh5CY7tFAIIYSofyRgsYNI89TmsnksegM8tBye2AZt71DbEpbZoXVCCCFE/SMBix1EVjS1GcAjABo0hWax6r0ELEIIIQQgAYtdNAtQAcuWE+cAOJ9bxNYT5607NO2nnlN3wZlDsGceFJUJbkqKYPV7sOvnumqyEEIIYVcSsNjBoDaB6HWw4eg5diVlcOfn8Yycvp7tiaagxaMhBHdQr2f0gl8egDUfqPd55+D7EbDiLZj/KOSetcs1CCGEEHVJAhY7CPV1Y0i7YAAe+HYzh9NULsvGY+esO5mHhUoL1fOhxaBp8MMdcHyN2qaVwr7f6qrZQgghhN1IwGIn43tFAJCeW2TZtic507pDh3ugQTPoeB+gg9N74OAiSN4KDq7QaazpoF/rsNVCCCGEfUjAYiedwn3pFO4DgL+Hmua891SWdYcGTeGJrTDsv9Cok9r25z/Vc4sh0Ps59frEeshMrqNWCyGEEPYhAYsd/XtEO+7uFs53D3YF4NjZXLILisvv2GyAes4+pZ6j7wSfMAiPATTYO69uGiyEEELYiQQsdtQyyIupI9rRJsSbRj6uAOwr28tiZs5nAXD1hab91eu2I9Xz7l+ucEuFEEII+5KApZ5oE+IFwJ6KApZGnVSgAtDmdnBwsr7WGSBlB6QfqZuGCiGEEHYgAUs90SbEG4C9ZRNvzfQG6PoQuPhA14et2939IbKvei29LEIIIa5hErDUE20bmXtYKghYAPq9BC+cgMDWttvbmcr47/kFVr8Pn3aHtANXsKVCCCFE3ZOApZ5o20j1sCSk5ZBXVFL9A1veAgZnOHsIVrwJZw5A3NQr1EohhBDCPiRgqScCPJ1p5OOKUYMNR9Orf6CLFzQfaLtt/+9w7ljtNlAIIYSwIwlY6gmdTke/lgEALN+fVrODez0NjbrAyK/VDCLNCBumWz8vylVVcoUQQoirlAQs9Yg5YFl5IA1N09CqG2Q06gQPL1f5LD2eUNu2/w/OH4ejcfBeFPw6/oq0WQghhKgLDvZugLCKadoAF0c9pzIL+HLNUWasOkq3Jn68MbwNAZ4u1TtJZF9o1FmV8J95KxRkQHEuHPhTrfJsnhIthBBCXEWkh6UecXE00LOpPwD//usA53KLWLw3lQEfrLau5FwVnQ7u+gH8IiEzEQpNdV1KCiBl5xVquRBCCHFlScBSz/RrFWB53bWJL21CvMjML+aNhfuqP0TkFQz3/wFB0RDaDRr3UttPboAt38K0xnBste0xWSlQUEHROiGEEKIekIClnhnYOggvFwdaBnny1diufPtAV5wc9GxPzCD+SA1mD3mHwiOrYfzfEGVai+hEPKx+Tw0TLX3Vmoh7/jh80gm+H1nblyOEEELUCglY6pmGns5seLE/fzzRC283RwI8XRjdNQyA/65MqNnJdDr1COuu3h9aBFmmlZ1PbVMJuaDyW4rzIGkTnDlYOxcihBBC1CIJWOohNycHHA3W/zSP9GmKg17H+iPpTJm3i5Pn8mp2wpCOYHBS050BHN3V85r/U8+Hl1r33f/HZbRcCCGEuDIkYLkKNPJx5eHekQD8uOkkN3+0hqTzNQhaHF0guIP1/YgvQO8Ax9fAkRVwYp31MwlYhBBC1EMSsFwlnh/ckp8fiaFlkCfZhSV8urKGqzOHm4aFAtpAy6HQYYx6/8t4KC0C94ag06uVn/fOh+VvQs4FBeyOrVHJulKETgghRB2TgOUq0i3CjzeHtwVg7paTNetl6fqwqtEy+N8qr6XvC+DgAvnn1Octb4HwHur13HGw5n3YOMN6/NkEmHUbfHcrzLgRTu2ojUsSQgghqkUClqtM1yZ+9GrmT4lR467PN9D+9b/591/7qz7QtzGM/U0FLQBeIdD9UevnUQOgzXDbY8rWbUlYas2BOb0bFjx2OZchhBBC1EiNApapU6fStWtXPD09CQgIYPjw4Rw8ePFZJTNnzkSn09k8XFxsq7ZqmsYrr7xCcHAwrq6uxMbGcvjw4ZpfzXVicmwUAMkZ+WTmF/PF6qM1WzDRrNdk8AgEN3+I6A1dHoTbP4dbPlSfp+6x7ntkpXqOmQR6R0jbB2cOXdZ1CCGEENVVo4Bl1apVTJw4kQ0bNrB06VKKi4sZOHAgubm5Fz3Oy8uLlJQUy+PEiRM2n7/77rt8/PHHzJgxg40bN+Lu7s6gQYMoKCio+RVdB7o08WPGvZ359+3tuL1jIwBenL+bwpLSmp3I1Rcei4fHN4CzJ+gN0H60WpMIICcVcs+qkv7H16pt0XdB05vU630LaueChBBCiCrUaC2hxYsX27yfOXMmAQEBbN26ld69e1d6nE6nIygoqMLPNE3jww8/5KWXXmLYsGEAzJo1i8DAQBYsWMDo0aNr0sTrxuC26n4OjQ5mzeGzHD2Ty+t/7OOtYW3R63XVP5F7g/LbnD3BNwLOH4PTe9SMouJclZgb2BZaD4fDf8PeBdDnuVq5HiGEEOJiLiuHJTMzEwA/P7+L7peTk0Pjxo0JCwtj2LBh7N271/LZsWPHSE1NJTY21rLN29ub7t27Ex8fX+H5CgsLycrKsnlcr7xdHXn79rbodDB7YyIvzt9NqbEWZvEEqeReUvdYh4Mi+4JeDy1vNg0L7YWzMnQnhBDiyrvkgMVoNDJ58mR69uxJ27ZtK92vRYsWfPPNN/z22298//33GI1GevToQVJSEgCpqakABAYG2hwXGBho+exCU6dOxdvb2/IICwu71Mu4JgxqE8T/jWqPXgdzNp/k2bk7KSk1Xt5JA9up59N74Kg5YDENBbn6WpN398y7vO8RQgghquGSA5aJEyeyZ88e5syZc9H9YmJiGDt2LB06dKBPnz7MmzePhg0b8vnnn1/qVzNlyhQyMzMtj5MnT17yua4VIzqF8vHdHXHQ65i3PZn7v93E1EX7WXXozKWd0NzDcuAvSN6qarQ07Wf9vN0o9bzjBzBeZnAkhBBCVOGSApZJkyaxcOFCVq5cSWhoaI2OdXR0pGPHjiQkqHVxzLktp0+fttnv9OnTlea9ODs74+XlZfMQcEt0CJ+N6YSjQce6hHQ+X3WUh7/bQmZecc1PFmgKWArVsB9dH1KrQJu1vg2cvSHjBByLu+y2CyGEEBdTo4BF0zQmTZrE/PnzWbFiBRERETX+wtLSUnbv3k1wsPrxi4iIICgoiOXLl1v2ycrKYuPGjcTExNT4/Ne7gW2CmPdYT/7RrxnB3i4UlRpZk3AJvSw+4SogAXBrADe9aPu5oytE36leb/3u8hothBBCVKFGAcvEiRP5/vvvmT17Np6enqSmppKamkp+fr5ln7FjxzJlyhTL+zfeeIO///6bo0ePsm3bNu69915OnDjBQw89BKgZRJMnT+att97i999/Z/fu3YwdO5aQkBCGDx9eO1d5nWkX6s3TA1swtJ0KCuMOXkLAotNZy/nHvqbyVi7U+X71fOBP2DkHMpMurcFCCCFEFWo0rXn69OkA9O3b12b7t99+y7hx4wBITExEr7fGQefPn+fhhx8mNTUVX19fOnfuzPr162ndurVln+eee47c3FwmTJhARkYGvXr1YvHixeUKzImauallAF+tPcaqQ2cwGrWaTXcGGPYpnDkIETdW/HlQO2jUWeW4zH8EDM7w5A5VRdfMaFQzi4QQQojLoNO0q38lu6ysLLy9vcnMzJR8ljIKS0rp+MZS8opKWfhEL9o28q79Lzl7GDZ+Dvt+g9w0uO2/0Ok+9VnCMph9Fwx4E2Ieh8Uvwo7voaQQQjrBffPU0JIQQojrUk1+v+WfvtcwZwcDPZr6AxB3MK2KvS+RfxQMfd86PHRstfWz9Z+AsQSWvw7bZsGGT6EgE0oKIHE9rHjryrRJCCHENUcClmtc3xYNAZi3LZmsgmJ+3JTILZ+sYX9KLRfba2IaNjq+BjQNsk7B0VVqW0kB/P6Eet35ARj5tXod/ylsmAE7foScCwKqjJNw7ljttlEIIcRVq0Y5LOLqc3O7YD5cdoijZ3MZ+vEaTp5TCdL/XZnAp/d0qr0vCuumcliyUyA9AQ7+BWiqxH/GCbXSs0cgDHgdXLxVMbrt38Pi59Xxbg3glv9Aw1Zq2Gj9f8HRDZ7YCp6BF/1qIYQQ1z7pYbnG+bk7MfOBbng4O1iCFYC/96ZyNqcQgFKjxqHT2WQXXEK9FjNHVxW0gBoW2vmTet3zH2qFZ50ebn5PBSsAg/4NrW6Dxj2hQTPIS4efx8KnXWHdR6CVQlE2HPjj0tskhBDimiFJt9eJDUfTmbroAHd0DuWXrUnsPJnBk/2jSM8t5Pcdp8gqKKFrE1/mPtrj0r9k1buw8m3wagRZyWBwgmcOgYsPFOWoRRUrUlIIK95U9Vx0OvAOB/9msHe+Gmoat/DS2ySEEKLeqsnvtwwJXSduiGzAbxN7AuBk0LHzZAYfLbdduHDLifPkFpZg0OtYfegMN7UMwNFQg044cx5LVrJ67vqwtX5LZcEKgIMzDHxLPczOH1cBy4l1kHMGPBpWvx1CCCGuOTIkdB26JToED2cVq/p7OPHtA10J8HRG0+BAahb/WXaICf/byrfrapj0GtoFmg9Rwzz3/gqD3r70Rvo2geAOKvflgPSwCCHE9U56WK5D7s4OvD+qPasPn+GJfs0I9nalTYgXaQfPsO9UFqsPnQUg/kg6E3o3rf6JDY5wz8UXw6yR1sMgZQes/Y+addR+NDSoQXsu1daZ4Ne08oJ5Qggh6pz0sFynBrcN4t+3tyPYWxVuaxOikmE3HD3HgVQ15XlnUiZ2TXFqOwL0jmqW0ep3YXoPlZBrLLXdr6QQsk+rpQF2zoFFL0D6EfXZ2cOQsLz8uSuTvBX+eBJmDVNLDgghhKgXpIdFANA6RCU7LdmbijlGOZdbRNL5fML83OzTKN8m8Hg8HI1TlXSPr4Glr0BRrnUxxpw0mHEj5KTaHpsYr4alvhmkZiCN/hFa3lzx95zeB6m7IPouSN6mtmmlMHcc3DcfmvS6QhcohBCiuqSHRQDQOlgFLCVG2x6VHScz7NCaMvyjoNvDcP8fMGiq2rb+E8g2BSh/v1wmWNFBYFtw8lRDSV8PUMEKwJIpUFxQ/vzGUph9p1oL6cgKSNmptjt5QmkRLHvtCl6cEEKI6pKARQAQ7udmScQF8HZ1BGCnvQMWM50ObngMGnWB4jxY/R4cWwO75gA6eHgFvJYBj62Dm0yrhZ87qj5z9VWzjjZ8Wv68Ccsg86R6fTRO9bQA9H9FPSdtVvkzQggh7EoCFgGAXq+jVbB16vGY7uEA7ErKtFeTytPpIPY19XrzV/DdLep153Fq1WizbhPAv4V63XU8DH5HvV7zARTlQd45WPIvOLVd1X4xOxqnhocAmg+EUFMhPMllEUIIu5OARViYE2/93J24vWMjAHYnZ1JSarRns2xF3AgtyuSihHSy9oaYmWcrDfq3qu0SfacqRleUo4KSdR9C/H/h25vh0GLrcam7wFisqvH6NIZWpoBov1TbFUIIe5OARVh0j/ADoE/zhjRt6IGHswP5xaUcOp1DVkExQz5aw8OztmA02rk48h3fwqPr4LljMGEluPmV38cvEmImqiUDdDpoMURtP/gn7JmnXhfnqeTa8B4qoDELilbHtDQFLMfXql4ZIYQQdiMBi7AY3DaI78d357Xb2qDX6+jcWFWp/XVbEj9sSGR/ShZL953m5y0n7dtQRxcIaltxoFIZc8Cy8yeVs+LkAe1GqW09nrCdCRTcXj03aKqSeLVS02KOQggh7EUCFmGh0+noFeVvSbh9sFcEAD9sPMHXa49a9ntn8QHO5xZVeb5dSRn0fW8lS/amVrnvFde4Jzh7qSEfgJZDYeRX8OIpNd25SU/rvuaABaDNcPW8+WvQNDi4GP56Dn7/B+z+RX22+xf4uJPKkTHW4vDZ4aXw17OqzowQQlznJGARleod5U/7UG8Kio2czSki2NuFlkGenM8rZuLsbSRn5F/0+Jnrj3M8PY8fNyXWUYsvwsEJmsVa37cdqZ6d3NVz40oClk7jwOAMp7bBxs9hzj2w6XPY9h38Oh5+vAfmPQznjsDy1+GHO6AwRwU3az6ATV9W3J5NX8Iv49W+lfnrWdj0Bez7/ZIuWQghriUSsIhK6XQ6JvWLsrwf3yuCt29vh5NBz/oj6Qz4YBUrD6QBcOxsLpuOWfM8jEbNUuJ/T3JW3Ta8MuZkXVdfiLzJ9jPfJtD1IegwBhpYrxmPhtD+LvV68fNqeKhxL+jyoNp28E+13lFEb3BwhSPLVVLvkRUqgPnrGUjcYPtd54/D4hdgzy+wbVbFbc09C+dNazmd2n4ZFy2EENcGCVjERcW2CqB/ywDahHgxuls4nRv78uc/etG1iS95RaU8OWc7S/amcusna7nri3j2p6jgZF9KFmdz1FDG2ZxC0rIqKNpW19oMh5hJMOwz1eNSlk4HQ/8Phn8G+gv+t7hhovW1ewDcOQtu+Q/c8Q24+Kgg574FcPsMtc/Gz2FlmYUfl/wLyi5xsPo9MJao15u/rHgYKWmL9fWpbTW8UCGEuPZIwCIuSqfT8fW4rvz5jxstheWiAj354aEbaB/mQ1ZBCY/8bys5hSVoGvy2QxVZW3XojM159p6qB70sBke1gnRlJforE9BSLcSoM8Btn4B7A7W97Ug1U2n4Z6A3QKvbIKA1FGapNYn0juDoDslbYK9pZlL6Edjxo3rt4KKK2yUsK/+dSZutr1N2QmlJza9XCCGuIRKwiEvi5KDnk9Ed8TQFMT5uKlF34a5TaJpmCVicHdQfsT3J1gJ0qw6dYcWB0/ZdWLGmRnwFT++HFoNtt5ftjdHrofcz1vcd7oaeT6rXfzwFBxfBvAlqWKnZAOgyXn226fPy31c2YCnOg7OHqt/W4gK1AOThCgKhC+WmqwRi85IEQghRT0nAIi5ZeAM3Zj7YlYd6RfDHpF64ORlIOp/P2oSzbDtxHoC7uoYBqoelsKSUlxbs5v5vNvHgzC08PGtLuaGizcfP8eGyQ5SUGtE0jU9XJrBod0qdX1s5Dk7gGVj1fq2HQ3AHNW2652To+Q8Ij4HCTPhxtOptcfGGAa9Dt4cAnephObrKeg5jqXURRvcA9VzZsFDyNoibBoXZ1m1758HG6SpBuKr8l/hPVALxwqervjYhhLAjCVjEZenc2I+XbmlNmJ8b/VupH/QJs7ZSYtSIbOjO4LZBgKqY+/CsrXy/Qc0YcjToWLY/jYdnbbE53/O/7uLDZYdZsvc02xLP896Sgzz/666rpzdGb4AHFsHk3aqOi6OrWjU6oo/63C8SHloOgW3Ua3Py7h//UKtQA5w5CEXZajjJXCumosCjMEcFJXFTYc4YKDFNNT+xTj2XFsLPY1UwdOYgpB0oXwDPPByVvAVO7629+yCEELVMAhZRa26JDgYgv7gULxcH3h7ejjbBqtx/ckY+qw+dwdXRwLfjuvLHE71wMujZmZRpSdQ9k13I0TPqR3tb4nm2ncgAIKughDPZV1EtEic326J2Tu4wZi7cMxcmxKkVqM1iXwOvUDVzaNFzKlfl5Eb1WaNOEGpaIym5gh6WdR9Ctqn36dgq+G2iSu49Ea+2ObhCRiLMug0+7QafdYf3m8PGL9R+2amQutt6vm3/q53rF0KIK0ACFlFr+jRvSJsQL9qHevPHE72IadoAbzdHwvxcLfu8MawNN7UMoGWQFze1bAjAgh3JAGw5bv3X/46TGewos1L0EVMgc9VycFYLKrp422538YJbP1Svt38PM3rCoufV+7DuENJRvT69x3bY5/xxWPexen3D46B3gN0/w55fVU0YdHD/H9B8CPg1VbOZXLxV4bxFz8KCxyFhuTre0VSLZtccKVInhKi3JGARtcbF0cDCJ3qxYGJPGjdwt2zvGKZK/N/WPoQ7Oodatg/voBZY/GPHKYxGjc3Hz1s+25OcydYT1vdHz16kwNrVLmqAWh/J2RvOHFBDOU1uhB6TwDdC1YgpLVKF5Mw2fan2i+itFnnsNFZtNwc7gW0grKtaBPIf2+CFE/D8CbWv3gF2zoalpkUju09QvTz552VlaiFEvSUBi6hVOp0OnU5ns23KzS15+/a2vDMy2uazm1oG4OniwKnMAjYdP8eWE9YelsISI6llEnKPXu09LFVpOwIeXaPqxNz9k+odcfVV9WGGTwedHnb+aJ0Sbc5T6XS/2secC5OnivXRuEf579Dp1IKQg6fZ7hs1SH0/wNGV6nnJv9TsodpcakAIIS6DBCziigv2dmVM98a4Ohlstrs4GhhiSsr9dGWCpVZLi0DPcuc4euYa7mEx822s6sS0GKyCC7PGPaDvFPX6739BQRak7FLvw7qr56B2ENrVekx4TOXf0/UhaG6anu3srY4zL01wIl7Vion/r5o9VNHspKStsOpdKC2u/rUd+BOOrKz+/kIIcQEJWIRd3d+jCY4GHWsOn6XUqNHIx9UyswigcQM3AI6evcZ7WKrS62lw9YO8dNjwmarl4tUIfMKs+5h7WaDiHhYznQ6GfQotb4HYV8DgAGHd1Gfph2HXT9Z9Dy0uf/xf/1SVfHf9bN2maaoIXnEFFY3PHlazmX4cbZ0Jdan2zoct31zeOYQQVyUJWIRdtQnx5q3hbS3vuzbxpUO4j+X97R1VnsvJc3kUlajhibyiEvbVh8q5dcngAM0HqdfrP1HP5t4Vsza3q5yWDmPAM4iLcveH0T+o3hZQs5oCWqvX8Z9Z97swYCkpgtQ96vUxU+2YE/HwzWD4uCMseKz8d+0xVfktKbBdcqCmSopU4b2FT6leICHEdUUCFmF3d3UNZ0LvSACGRofQIdTH8tnA1kG4OxkwapB4LpfCklLu/nIjN3+8hrlbTlZ57rcW7uPOGfHkFlpL25caNZbvP01mfg2GNOoD8+KNRabhsfAbbD93dFW5L8M/45KYh5GKysxGSt0NWaes78/sVzONQNV3ST+ipk2fNC3wuG8BZJ+27q9papFHswsXgqyK0QjnT6jzZCSq5GOwrQRco/OVqoUlhRBXHQlYRL3w4s2t2PfGIAa0DsTX3YlnB7Xg4RsjaBXsSURDNePoyJlcXv9jHztN053f+GMfpzLyKz3n+iNn+WrtMTYdP8eaw9YfqWmL9jP+uy1M/Wv/Fb2mWtesv1p/yMw8jFNbyg4jeQRBoy7q9aEl1u1lS/jnpMLfL6kgIrQbBEWrlat3z7Xuc3qv7bICifE1a9P6j+CjaFW999xR6/bkrTU7j9ny1+H9KLVMghDiqlKjgGXq1Kl07doVT09PAgICGD58OAcPHrzoMV9++SU33ngjvr6++Pr6Ehsby6ZNm2z2GTdunGV2ifkxePDgSs4orlVuTg6W1xNvasa/hrZGp9MR6e8BwIfLDjN7YyI6ncptyS4s4YV5u22q4GYVFDNj1RG2HD/HmwutAcnOpAwAdidl8vXaYwAsP5B29VTQBVWALrKveu3oDoHtavf8ZXtsmsVa101a8iK8HazqvpiTfc0O/qWee/4DOt+vXu/8EeI/hS/7w5//VNsamIrlJW2GtP0we3T1elv2LlDPCSsqDlhS91ScN1MRTVN5N5pR5eDY+799+hGVQF2RtANSeViIC9QoYFm1ahUTJ05kw4YNLF26lOLiYgYOHEhubuWJdHFxcdx9992sXLmS+Ph4wsLCGDhwIMnJyTb7DR48mJSUFMvjxx9/vLQrEtecSFMPi7ki7tOxzfn6/q44OehZfegMP5cZGnrtt71MW3SAO2bEW/YH2JGYQUmpkRfm7cJo+p06k13IodM55BWVkHQ+r+4u6HK0Hqaem/RUeS21yTsUfBqr11GxavVpnV4tvlicB2v/Yx2KMee7ALg3VLOO2oxQK1Sf3qOCnOQt1qGiPs+rGUlFOfC/2+HQIlj93sXbU5AFqaYAKW2fbcCSulsl4M7oCV/HqhoyVTlzwFoZOHW3dQr3pcg7p3qeajJTqqzkrfDfrvDLA+U/K8qFrwfA573h+NpLb6OoX/LOwazhtsnqokZqFLAsXryYcePG0aZNG9q3b8/MmTNJTExk69bKu2d/+OEHHn/8cTp06EDLli356quvMBqNLF++3GY/Z2dngoKCLA9fX99LuyJxzekQ5gOAv4cTn43pxKR+zWgW4MEzA5sD8NbC/ZzKyCchLcdSNdfJoP5o39lFFarbnZzJ3/tOs/dUFt6ujrQPVRVn1xw+w7hvNtP3vTgS0q6CqdPt74aRX8MtH16Z8w//DG56SQUrDVvAwyth7O/gGQL55yBlh9ovZpJtmwyOKnHXnBis00OPf6gAq90oaHWrdQjLHDSciFeJtIueh0+62Oa+AJzcpHpDQAUb58ok2pYtpJe6G76/w7YScEUunFa99sPq3BFbRqNKev64A8y+Uy2HcCl2/qRmeiUsL7++08lNUJgFxhL46T44d8z2c01TSziIq0vCMhUkx39q75ZctS4rhyUzMxMAPz+/Kva0ysvLo7i4uNwxcXFxBAQE0KJFCx577DHS09Mvp2niGtKneUMWTOzJ8n/25eZ2wZbic+N7RdIp3IfswhIe/X4rr/6+B6MGA1oHsvaFm5gz4Qb+fXs73JwM5BSW8OEylUsxulsYt0SHADBj1VE2HT9HiVEj/uhV8GdOp4N2d4B3oytz/ia9oM+zahFHgJAOENkHOtxt3cfRTQUhHoGqaq65yi6oejHNB6t1kwa+CXfOgpFfgaMLhF8wq6k4Fw4vUVV70w+rpQHKSlxfZt886xpJzqblDXLPqB4dV1/Vm7Ny6sWvzdyj0u0R0BnULCdzD0ZmcvWGlrbNVHk7BervPnb9BLvmXvSQcoxG2P+H6Y0GR1bYfm4uCggqSCw780rTYP4jMC1czea6sLBfaQmc3CwF/+qjHFNAbg7YRY1dcsBiNBqZPHkyPXv2pG3btlUfYPL8888TEhJCbGysZdvgwYOZNWsWy5cv55133mHVqlUMGTKE0tLSCs9RWFhIVlaWzUNcu3Q6HR3CfPB2dbTZbtDreG9Ue9ycDOxKymRdggo4noptToCnCzdENsDBoKddI/UDd+i06kEZ1r4RPZv5A3A2x7p2TtkhJHGBDmOsrwPbgIMTjPsTxv9tu5hjUFu45yc1pHShqEGq5yWkk6oBA6qirmb6/3zPr7b7n1hv+77YNPTc+lbrtrYjYPgM9Xr792o4Zd3Hqucj54x1v5IiOG6uDnyfNd9m4VOwdSZ82BY+u0HNSAIVwKx6V7XPvAq20QgbpqvXvZ6G3s+p138+XbNp1slbIbvMzKvDf1d83b1NPUiJ8ZBrCqa3fK2CpOJcWDIFfrzLtrdl7X/UENnCJ6vfHlE3zAFLTtqlDyVe5y45YJk4cSJ79uxhzpw5Ve9sMm3aNObMmcP8+fNxcbHOdhg9ejS33XYb7dq1Y/jw4SxcuJDNmzcTFxdX4XmmTp2Kt7e35REWFlbhfuLa17ShB4uevJHRXcNwMui5p3s4rUO8bPYxDykBNA/0oFWwJy2DPGng7mSznwQsF9GgqbUablC0evaPgkadq3+O4GiYtAXGLYSm/dS2jBPWz1N2Wn/4iwusibXm2UoABmc1XGXW/RGIGqjWWyrMhN8mwdKXVfDyRV/rrKakTepH3r0hBLSB/q+o12cPwR9PqqGn88fgm0HwVawKYFa+rSr+7vtNnePoSrW/kyfc+LTKywnrroZvZt9ZfmjHbPV7MDVMVQgG2P+7ejbnCyUst/aIFJepVRM92pordHw1nDmoAihQ98DBVQU7+xaobZoG200rbm+bpXJ8atuCifDjPVe2Byd1txruy70KejxrwhJAaypoETV2SQHLpEmTWLhwIStXriQ0NLTqA4D333+fadOm8ffffxMdHX3RfSMjI/H39ychIaHCz6dMmUJmZqblcfJk1fU4xLWrcQN3po2M5uBbg3l7ePnevrIBy7AOjdDpdOj1Ovq0UKtFx7YKAOBgajZGc0buBdYfOct7Sw5QUFxxr991YeBbavZQ90cv/RwNmqrZThF9bLcHmWY8mYvMJW9VeSoegdDqFut+vk3UsFWjzip3plFn0Ouhy3j1+V7T8Q6ukJUE390G2amw5Vu1PfImtb+rr1oI0qz93eDfQnXXJ21WAYyb6oXjaJx63vi5eu54Lzh7qqTnO/8H3mGQngA/3Vv+X85GozquMAtWvqWCCnPA0u9lFfzknYWU7WWuu1Bdd4Om1vt0dBUse10V32vaD0Z9BzeaZmCt+UCdN2mLbQD4x5Pq2mtL3jnY8T0c/FNdb2kJbPxCrRxem9Z8AJu+uPYqGueUydG6GoaF/noWPoy2LWtgZzUKWDRNY9KkScyfP58VK1YQERFRrePeffdd3nzzTRYvXkyXLl2q3D8pKYn09HSCg4Mr/NzZ2RkvLy+bhxAVLbwI2FTOva19iOX1v25uxf+Nas9/7+mEs4OevKJSTpxTs4U0TWPrifMknc9j8Z4Uxn69iU9XHuGL1UcvPP31o1EnuPdXaNj88s/VoKlK5AUI7wHdTXkau+eqH/lNX6j3TW5UPSJmfpEq4Hl4Bdw+w7q9472q98W8z5M7VE9QQQb8b4QqXqfTQ8zj1mPajYLY12DAGzDsM3hgEfR5QS02OXk3jDC14ehK1fNzeAmgg24PW8/hGQj3/AzOXir3ZMWbtteZvEXl2oDKVfnjH+oH3tENWgyBpn1N120aDjMPBzXuofKVIk0By4GF1inkg99RQVe3h8DJA9L2qh8Vc4G+NiPUPSvILD/cVF0lhSq3qGzAU3aW1tmDamhq0bNqkczalGn6B2jSpovvdyFNgxVvWRcIrW9yywxRli3GWB+kHYDCMpMONE3dx4wTqvdw+ZuVH1uHahSwTJw4ke+//57Zs2fj6elJamoqqamp5Odbi3eNHTuWKVOmWN6/8847vPzyy3zzzTc0adLEckxOjro5OTk5PPvss2zYsIHjx4+zfPlyhg0bRrNmzRg0aFAtXaa4ngV7u/LuyGg+uLM9YX5ulu0NPJwZ2TkUF0cDLYLUgov7U7IoKjHyz7k7GTl9Pb3eWcmj32+jxNTz8uWao2TmyfjzZdPpoOVQ9brTfeq1g6v6IZw7Vg1z6PRq6CWglfU4v0r+keTmBzc8pgKH4dPV0gS3z1BJuWmmeibdJkBIR9s29HoKej6pAgD3BnDTFOhwD/iEq6DB4AxZybDIlK8SNVAFW2UFtlZrMwGs+wgOL7N+duBP2323zVLPA94AZw9oe4d6v+FTWPlv6zpO5uG3xj1VgnDuGUBTPUTmgNHVF7qaepYWPWct2Nd+tDXBOSOx4vtVlXUfwV/PwC/jrdvK5umcOWhdGPPEOjVDa8Xb8H6L8rOaasr8Y560ufJaOZpWPkk6eZsaflv4VPVnUZ3aDh93gkOXGNjVRH3sYSnOVwHnZ93h1zL/rbNOmSpem/4BuOb9ejGMVaOAZfr06WRmZtK3b1+Cg4Mtj59+si6WlpiYSEpKis0xRUVF3HHHHTbHvP/++wAYDAZ27drFbbfdRvPmzRk/fjydO3dmzZo1ODs719JliuvdnV3DGNGp8uHLVkGql27nyQzGf7eZeduS0etUYi/AiI6NaBHoSXZBCV+vVf/S3JOcyV2fx/PzZhmSvCQD3lA9Je3vBlcfuOUDtd08g6bTWJXg6x2qhk5A9Z5Uer7X4YVEawG8wDbQxxRoeIbATf+qWfscXa3nSjAFId0nVLxv69us6zLNe9g6TGKuqNvraeu+LW627ttmOPScrF6vekfNlnL2sq6m7eKlerbMLhyOi5mkho8yTqiFMV19VVDjE64+LxuwFGbDLw+qabXGCoY28zPUw2hUOUAAJ9Zak5XLTis/e8i6ppSxRAVm6z9R1Y/3LVCJyj+PhaWvVHy/KmMstfbq5J9XQ08V2fotvB0IB/6ybju9Wz2X5NtWVy7Oh8ykis+z8yd1XZu/rFk7a8pYqv77mF2JHpaSovKlAS66f6FaA2zbd+r9kZXWIPCsqSCsfxQ0bKleX2p16VpUo8pT1akKemGi7PHjxy+6v6urK0uW1J8xMnF9ahWsfhC/WnuMUqOGm5OBT8d0olsTPxLP5dEyyJMle1N59PttfLHmKIWlRn7cmEhWQQnbT2YQ07SBTe+NqAYnN9uk3Q73qOqu8f9VAYo5wNDpVA2XI8shuMPFz3nhkGCvp1VvS2g39eNfU5F9rYs8NoiCyH6V7zvwbZVHkrJDJaYOeUf9xa93UL04xhL1L/phn9q2M/Y19eOx+Ss1TNXnOdtVuCP6qN4G3yYQNcD2Oz0C4PENagXvnT/BDY+qGVwVBSyHlqiZWHt+VUHhqJnWRTILc+DTbqrnYvBU21yY1e9Ck98u6GE5AOllhoj+flkFCgCJGyG4vTVZudsEFXRWR+4Z66wxUDVpys5CMzPnOm3/Hlqa1tgqWxk4dZfqmdsxG5a/Ablpap2tJr1sz2MOiJK2qGuvYEi5VuSetdYUgop7WPb9roYKK5phVxVNg5/GqGHHB/+G0Gokw++eq/6suppqnuWfV3/OIm5UPWgA/s3BxUf9907aooYx7UjWEhICaBWsfsxKjRo6Hcy4tzM3tQjA3dmBVsFe6HQ6BrUJ4sYofwqKjXy+6ihZBSUY9DqKSoy8t+TiS1SIahrwBgx5V02N9giwbh/xJTy4BMK61ux8BlOdmICWl9aepjdZX3d/RA0dVcbRBUbPVj0eaXvhO1OycJNeqgdp4JtqhpTbBXWrdDoYMg1eOg23Ty8/7NXtYWgxVBULNNfHKcvND/q9BE/thhhTITvzDKSMMr1/F67ptKRMj9OBP9WQRW6aWhEbVHKv3kElHZ/cZNvDkrrbdpHM3DLDBSc32taWsdScqYYLex4qWuTSaIRTO9TrY6utic5lA5aUnSoH57fHVa/PhWtcmZkDlvxz1U8ermgBzdJi9X1l83zKyr1gOOXCgGXb/+Dn++CHkWrWmNnZBFj6KuxfCEUXVOPe/Qt80Abi3lE9eYf/VkHxxhlUSdOsBex6PaWS6cFal8gcsDRsYe3hqwc9LBKwCAG0DPay/OPqmYEt6N28Ybl9dDodMx/oxod3daB5oAexrQKYM+EGdDr4fecpdpgWZRSXQW9QgUGTnrbb3RuUX526LgS1VzOYfCNUbkhVvBupoMWnscrJ8Qy2rQp8MRUFI6B6Qe6ebRs8VdkOUw9N9ilrHRlzwGJe3uHAQjUEBNbcGbD2cPR+VvX4gConX7ZHxdxb0KCZNdkZHRic1I//jtnWfff9bn29/QeY3su2xk5JkZoZdCK+/A95RQFL+mFrsFSUbe0dOb3Huk/KLjWjCSCit3o+vNQ2J6akyLYnqbo/yPMmwHtN4aMOsMq0vMTOH1XOzzdDVA2fC12Y/5FV5jqTtqpaPmbzH7Xu/9tEWPeh6j35bxdrQLfuI5VzkpUEcf9Wx5jt+826VIWmqeHMC6fcH1mulrtw8oTO46w9T8fXqGfznxX/FhBqmiiTvM3uBQklYBEC8HZ15I1hbXlmYHMe69O00v0Meh3DOzbi76f68NX9XenaxI8RHVV391sL96FpGrmFJaRmVnNBPlG/6fUwYTVM2qymMldHaBeYvAteSoV/Hig/jFMXPALUyt6aUSUNA5w9rJ47jFH1XUoKVK2WnDRrFeAephk/DZpBeIxaUgHUfoWm6r7m4SaA0K7WVb4j+6j3YJuvkRhvza3Y9LnKNfn+Duu/5jd8qlbRXjjZ+oNsHipM2webv1bDTOZgI3mb7bUeWaGu0Vx9GNTsrJSdgE7NAHNwVfuU7YU5f9x2mObC81bEaIRDi03HH1NT1c8ctE59z0mF2XeVXybCHIB4m+6dOTAryIS596sp/C1uhoatVG/MbxNVL9LJDaqXy72hav/Wmeq+mXODwmPUc2GmmobfsKWaFm9er2jPr/D9SJg5VOXymK3/RD13Ggsu3mo2HqgAsTi/TA9Lc/VnxcFFfUdlOUV1RAIWIUzuu6Exk/pFodfXbBz72UEtcHHUs+XEeb5ee4zBH63mhqnLGfbftSzdp/6i3p+SxbBP17H60JkqzibqHb1erZV0NdHprL0sGYlqGMP8Y+PfXOULgeoJ2TNP/XA36qyG5Mb8CmPmqnNE9FY/mHmmIRCvUGvhQIDAttDjCZXf0+cFVUjP8lk7U+Chqd6ckkI4vU99VpyrgpY981TvCqh/1ZuHVEI6qV4qzah6H74ZCJ92h4OLrT0hHoHq+cgKayDSIEr1+JSY/sEQ1l3lA1l6WcrMBrrwxzd5i1rX6qsBtsGPucZNcb4KUopy1HeYg4XDS63Bl8FZBWSz77KdJmweEgo23buiHLW456Ln1TRu3yZw++dwxzfqHIf/hrnj1L6th8Pgadb/Xuv/q153vFdNxTf34A18y1qPaOt3qt2bv1bv0/ZZg5zU3SrA0hlUzhOoZHbPYBU4HVpi/e/t31z92Tfnjtl5WEgCFiEuU5C3CxNuVLNX3vpzPyfPqX/J7EzK5NHvt5KSmc8HSw+x82QG36yresrnqYx8/rP0EFkFlz99ujqJ8uIaZU7czTypgpaSAvVj6BMO7e5UP1hJm6w/ZNF3qSAlKtY6G8vZ0/rDDNAgUuU1mAW1hWb94Ykt0DjGdtiuaV9rVeL9f6gfTWOxSuJsNkAl6f7ygCqqByo4Mee+eIWohTg7jFFLOji6m6a8j7PO2DL/UJ/aZh3KCOmgppmbmRNymw9Uz4eXWj8zByzmAOzkRpX/kbTJNu9m91z4qr+6T+bVwwNbW5eX2PK1yv8xOMPYBdaaPD/coZaKAGsPi28T9Tmo3qadP6rp+7d/oZLCA1urqfWggiNQQ6Qth6o1tDJPqpXOAXo8qf57DXobpiSr9b6iR6nepLS9atZZ4nosU5M3faGG58wBT5vh1t4ync46LBRv+tw7TNU8gjLDQluwJwlYhKgFj/RpSkNPNZYf4e/On//oRadwH0qNGv9ZeogVB9RfWNsTM6oMIqbM281Hyw/z6crL635df+QsXd9exsJd9axIlagbZWcKmYeDGjRTuTKegdYZH6WF4NfUmq9yIXNCJqj9/MsELIEXVJY2DwmBml5t/o4T6yFxg3od0gFG/6ACETN3U4L1mQPq2StE/YAO/wzG/KyG1sJuUEGO+Ye81S1quEIzwgZTomlgG9seoBamWj/NTMNyJzda8zvMAUvzQdYFNc3Mwz5gne2073frUg9B0db7Yu4VMg+P3bdAnS8xXvWggDVg8QhUPRmg6u6AmtZedmHQmCesQ2LB7dV5HV2h3UjrPs1ibQs4OnuoZ1dflUQLEDfVen3m4O7Xh6wFBi/MrWo9XD2b84b8y5zfnHibJAGLEFc9d2cHvrivMw/0bMKcCTfQJsSbh029Lj9vSaLUVHguM7+YY2dzLcftSc5kT7K1+/n42VxWmYaNlu+/vEJNy/alcTaniN93SMByXbIJWMxJlGWmCN/2CdzxrVrf6Ymt5WcvmZUNWBo0tQ5reIeDu7/tvm5+6oewxVCVF+HfXA0jlRZaZ68EtwcHZ7jrf3DjM2o6+IXBkvlH3czFS82kMvcWuPqqROjBU1Wir9HUGxnYVp0f1Hf7N1OvfRur4SKt1Jrwa56m7d/cOg24gen+HFmphrBKS+CYqfcmJ9W6QGdwtOpp8iozXducKB7aGUZ/r9q6/X+mPCFTDo9HAHiZrk0zqh6XPs/bXqvBAUZ+rXrBhv7HOtW6w73WfcyVoSvS6ylr7RSATvdD7OsqR6a0UM0katzTtr4PqACw7MrrZXvSGnVRU65dfSov5lcHJGARopZ0DPfl1VvbEOilFvYc0DqQYG/rIp8OptyY7YkZAKw8mMawT9cx4rP1HD2jxrt/2GidtZCQlsOJdGtwU1PJGWoa5MHT2VXsKa5JZac2WwKWMv9qdvNTq137R128/khgG2sA0SBK1TcZNVMFHBUZ9Laa1eTgpM7brL/abp42bM6HcHCG/i9Dj0nqO8ryCqGckI7WVcMbdTEtXdAX7pyl8mz0DipYaT8aujwIt/zH9njLTBhTITxzD0uDptD/VbjhcXjgL/AIUjkmJ9apujmFZfJZzHVtgqJtr63s+UHlzNxomvnz+5PWHi6PANtgbODbajr8hfwiYOSXtvVUGnVSbewy3rp4aEUcnFQwqjOooDVqoAqC7vjGlFyrg97PVHzskPes/33K1kjyCYcXTsLY365crZpqqFHhOCFE9TkY9IzpHs77fx/Cw9mBYR1C+GFjIttPnieyoTuPf7+NUqNGKRr//usAn9zdkZ+3qIqc3q6OZOYXs3x/Gg/2iiC3sIRv1x2jRZAXA1oHVuv7kzNULk3iuTzyikpwc5L/3a8rZZNuzbNhygYs1aXTqWJ3x1ZbZzy1ub36xzfrb62mCmpI6EJBFwwtXdjDYjbobTWcZV7SANSw08MrVL6IuXbPhcEKqIBi67eqem9htuoxATXM5epjbVfzgWoJhYOL1ewcUMGQ0VzuX2cNsJrFqmszONkOhwH0naJycsoGPe4B1vygiD7W5SmqQ6dTPUrVEdYNHo9X+TIG0//3jq4q4MhOVdPvK+LoomoFJW60DYp0Out57Mj+LRDiGja2RxMOpGbTp3lD3J0d+GFjIvFH0lm2L4384lI6N/Zl58kMlu0/ze2frSMzv5hQX1fuu6ExUxcdYPmB0zQN8OBf83eTdD4fLxcHdr46kMISIxuPnaNH0wY4GiruKD2VoWZKaJrqrYkO9anDKxd2Zx4Sykqy1i2pqGpsdTTrb9ubUBMRfdS/9rVSldvhW8F6UP4tyuzjZc3JuJCrD/SvoNy/eRjoYszrM6Xutk5hdm+ozllW88EqYDmw0Drk1XmcqkQMKg/InIwaNVDVtQnuoAKCsgyOMPQD+LIfYBpG8QhUhQCd3K1JzldK2SEdM72h8mDFzNnz0qrt1gEZEhLiCvJyceS/93RiVJcwOppWjT5yJpfUrAKaNHBj1oPduC9Gdd0fSM3G1dHAy7e0JtbUi7IuIZ37v9lE0nnVW5JVUELS+Xw+X3WU+7/ZxPO/7rL5voOp2Zw09aicyy2ybD+QKsNC1x2PQPUvf81oTTS91IDlcrj6WGeZBEdX/CPt6GJtW2W9K5fLK1j1bmhG+OtZte3CpGFQw0xu/qruiTnJ9obHrYnBwWWSeh1d1JCUefjnQo06QZcH1GudXg3DufqqisQX5v+IKknAIkQdCfZ2JdDLuqDn1BHRuDs7MDm2ObGtArm7Wxgrn+nLoDZBRPq7E+mv/hXnZNDzYM8Imgeqf3XuPZXFuiOqTsK8bcmsNM1A2ng0nSEfrWbUjHiSz+fbfPeh1GzmbjnJq7/toaTUWizr6Jkcxny1gQmztvDB3wfJroWp1KKe0OvVCtaewWp46IaJ1p6ButZmhHq+WC+NOXioKH+ltph7WcyL+5kXxyzLyV3lsgS2U+99I1Sg09w0qymshhWX+72scl7ajaq8mrGoFhkSEqIOdYtowB87T3F3tzBimjYAVL7KV/d3sdlPp9Px8d0dWXP4LMM7hhDs7cpzv+zk0OkcdidnsDvJmgj44vzdvHtHNM/O3YVRg9SsAtYfSbc5X/zRdGbFn6Co1Ei/VoH0ad4QTdN4+bc9rEtQ+/697zR6vY7JsZeQ5yDqpwFvqIe9dX9ETd01BwEVadRJTbltUHml6cvWpJeauQMqiDJX6b1Qwxbw8HLY8YMqYmeudxLZ1zr9t7rc/ODRNZfTamEiAYsQdehfN7eiR9MG3N6xinFkoG0jb9o2staHaG1aoPH3nafILy7Fw9kBfw8njqfncd/Xm2yO/XufSij093DibE4Re09lWT7bdTKDPs0bEnfoDOsS0nEy6BneMYSftySxdN9pJsc2538bTlBUYmR8rwryDYSoKZ1OzfK5mM4PqPyJ5ldwReCI3qB3VPklVQVyDs5qtpGZize0u6Py/cUVJ0NCQtShIG8X7u4WjotjzbuGW4eo4MVcSbd9mDezHuzOiE6NcHLQ4+ZkoGsTtVT8hqNqsbOKFnHcmZRBqVFj2l+qSNe4nk14fnBLdDo13LTyQBovL9jDmwv3cexsLglp2fSctoJZ8ccv5ZKFqB4nN1UHxKP8n9la4xUC4/6E8UutlYDFVUMCFiGuEi2DbRff6xDmQ3gDNz64swNbXoplzXM3MayD6rkxF6prEehJqK+aveBoUMmOO05msvJAGgdPZ+Pt6sjEvs1o4OFM53AV7Dz98w7Ld2w4ms6cTSdJzsjns5VHMBql1L+4yoV3Lz+NWlwVJGAR4irh5eJIuJ+b5X37MtOUvVwcaeDhbDOEBBDi40o707aHb4zEoNdxNqeQL9eocuIjOjXC200t7GeemXQ+z5p4u+FoOmsOqwTf1KwCdiZl1Pp1CSFEdUjAIsRVpFWZXpYOpmnSZbUM8sRQZrXpRr6u/GtoK94a3panBjSnZZA6fuMxNWR0S7R1CmlsK2tBOi8Xld5m7okxW7wntcJ2aZrG4j0ppGYWXMJVXR5N00jPKazz7xVC1C0JWIS4irQOVr0ljXxcCfAsX9LbxdFA04bWqauhPq6E+rpx7w2NcTTobYrHBXm50DHM1/K+aUN3ogLU1OlXb22Dk0FPVoGq7ulkKk63eG9qhYs3rjiQxqPfb+OxHypffr6wpJT/+/sg6xPO1uCKqzZ3SxKd31pms6yBEOLaIwGLEFeR2NYBOBp03Nq+8loVbUzJuU4GPf4ezjafdQizDhnd3C4YfZneGJ1Ox4z7OvPZmE6M6NSI9mX2vfeGxjg76DmRnldhEbrNx1Vhsu2JGRyqZO2iOZtO8smKBF6cv7saV1p9yw+oheVmrJIcGyGuZRKwCHEVaRPize7XBvHcoArKblv2UdOfQ3xcbAISgPZhPpbXQ6PLVxRt2tCDm9sFo9PpuCGygWX74LZBlhlHC3eVX/157ylrXZhftyaV+9xo1Phu/XEAjqfncbYWh3AOmgKok+fyWVPLvTdCiPpDAhYhrjIujoZygUhZfZo3xNFgG3CYRQV40q9lAANaB9KxTPBSEfPxHs4OdAz3YVgH1avz69ZkSo0a+UWlZBUUo2kae5KtAcu87ck21XQBVh8+w9Gz1pWnzStWX668ohJOnMuzvJ8tw0JCXLOkcJwQ15ioQE+2vTwAD+fy/3sb9Dq+Gde1gqPKi4lswFOxzWkR5ImjQc+A1oH4uDmSmlXAn7tT+HDpIc7nFTHrwe6czyvGQa/D08WBM9mFLN6byi3R1mErc++KQa+j1KixLfF8tVedvpjDp3PQNHB20FNYYmTZ/jRSMwsI8i6f3yOEuLpJD4sQ1yBPF0d0l7kSrF6v48nYKAa3DQLA2cHAcFOdl3/+vIOjZ3M5n1fM1EX7ARUojegUCsATP27nX/N3k5lXzILtyaw8eAaACb0jAdh64jzL9p1myEdraP/63/R9byWbTDOXLmTOS9E0jdWHzrBs32nLZ+bhoM6NfenaxJdSo8YL83ZJLosQ1yDpYRFCVNuoLqHMXH+c4lJrQGBet6htiBdPDWjO+dwi5m1P5oeNiSzak2pZUPHhGyMY2akR0+OOsCspgxfm7bbksmTmFzPmqw28P6q9pfhdbmEJby7cx6/bkugd1RC9XsdSU7Dy4V0dGN6xkSUBuGWQF6O6hDL803XEHTzD0z/voNio0aWxLw/0rL/LC6TnFPLR8sPce0Njmgd6Vn2AENcx6WERQlRbmxBvokPV7KH7Yxrb1Hxp28gbD2cHPrirA3Mm3EBUgAfncosoLtW4JTqYKUNaEenvgZeLAwXFRs7mFNKkgRuLnryRIW2DKC7VePaXXWQXFJOWXcDNH69hzuaTFJdqLD+QZglWAF6Yt4t9p7I4eFqtkdQyyJNWwV68OUxVMF2w4xR/7krhzYX7yCksqcM7VDNfrD7KrPgTPDlnh/QKCVEF6WERQtTIZ2M6sSspk8Ftgkg8l2cZ7mnbyMuyzw2RDfjzHzfyw8YTnM0p5B/9oyyJwh3DfVl1SB3zwpCWtAr24tN7OtFj2gpSswrYn5LN5uPnOJGeR7C3C/8a2oqdJzNIPJfHE/2ieHfJQVYfOsMj328hx1QnpoWpIN6dXcNIyVQVebcnnud8XjG7kjLo0dS/Lm9RtZnvw/6ULBbvTeXmdrYzt7ILinFy0OPsUPO1p4S41kgPixCiRkJ93Sw1XG435azodNAq2MtmPycHPQ/0jODZQS1tfnC7R/oB0LWJL4PaqPwYvV5nmY69PyWLXaYlAB7sGcEt0SH8a2hrPr+vC20befPx6A6E+bly8lw+5/OK0emwGU55MjaKb8Z1pUczFaRc7oykLcfPsdoUWFyKtOwCFu9JKdeDcjqrwKamzX+WHrKsAQWQdD6PmKkrmDCr8mJ8QlxPJGARQlyyga0D6dcygPE9I3Bzql6H7QM9InjlltZ8NqazTWKwOeDZn5LFnmQ11HPh2kgAPm5OzLi3M84O6q+vxn5uuDqV74EwT9vecTLDsm3vqUy+WH2EvKLyw0QJaTk8+r+tbDyabtmWmlnAPV9uZOw3m/jKtP5STf1r/h4e/X4bX621Pd4cBEUFqGGyw2k5LN1nXfpg8Z5UcgpLWHXoDAlpOZf03UJcSyRgEUJcMhdHA9+M68pLt7Su9jGuTgYe7BVBQ0/bKrytTT0s646cJTkjH7AdZiqrTYg374yMxqDXWQraXaijaa2l7YkZaJrGz5tPcvun6/n3Xwd4c+E+m30z84oZ/91mFu9N5aPlhy3bv1h9lCJTTZm3/tzPN2uPVfs6AYpLjawzFbP7LO4IWQXWhSVXmxaVHNQmyDK7Kv6INVhacSDN8nr+9vLF+IS43kjAIoSoF1qbelhOnlPBSqS/O54ujpXuP7xjIzb/K5bXbm1T4edtQrxxMK1O/e6Sgzz36y5L8PHjppNsOa6mUZcaNZ6Ys50T6aoA3dYT5yksKSU9p5AfNyUCqicJYNriAzWq0rsrKYO8olIAMvKK+XL1Uct3rj2selh6N29oCa52mQrwZRcUs/m4dZr3gu2nJClXXPckYBFC1Avhfm64lxnaqWg46EJ+7k6VVv11cTRYhpmmxx0B4LG+Tbmzi+rN+Nf8PRSXGlmyN5XVh87g4qjHy8WBwhIjO09mMnP9cfKLS2nXyJvP7+tM+1BvikqM/C9eVdOtaBHIC5l7TAJMvUlfrz3G0TM5LN9/mvN5xZYqwuZFKfedyrL0yhSXaoT5ueLp7EByRj6bjldcp0aI64XMEhJC1At6vY6WwV5sPaEWUmxXjYClKh3Dfdht6rW4IdKPZwe2IDO/mGX70zh4Optftibxx061NtJDvSI5np7Lwl0pLD9wmjmbTgLweN+m6HQ6Hroxkid+3M7/Npwgu6CE7zeeoEOYDzc288fZUU/bEG9Loq9ZvCkfZuJNzVi46xSbj5/n3q82WlbBvqNzKI4GPY393PB0cSC7oIRDp7NZeUD1vgxoFUROYTE/b0li7Deb6Bzuy5vD29LMtKr2lbAt8TyNfFwJ9JJqwaJ+kR4WIUS90brMTKPq9LBUxTzU4upo4J2R0ej1OnzdnZh0UzMA3ltykPVH0tHr4J7u4Zb1k75Ze4zM/GKaNHBjoGkm05C2QTTyceVcbhHfrDtGUYmRTcfO8X9LD/Hvvw5wz1cbmb0x0fLdhSWlbDGtYt2jaQNm3NuZCH93TmUWkFNYQvcIP168uRWggjVzfZvtiRmsPKjyV25q2ZAHekYQ5OVCUYmR+KPpPPb9VgqKS8td6+bj58jMLy63/WI0TeOJH7fT650VpGYWsP7IWUZ8tp5x326uVg+SEHWpRgHL1KlT6dq1K56engQEBDB8+HAOHjxY5XFz586lZcuWuLi40K5dO/766y+bzzVN45VXXiE4OBhXV1diY2M5fPhwJWcTQlyrWtkELBUn3NbEkLbBjI1pzGdjOtG4gbtl+z3dwwnycuFcbhEA/VoGEuLjSkxTFbCYK/k+0DPCUhzPwaDn4RtV1VxPFwc+uLM9r9zSmhGdGlkSf1/+bQ8rDqgCd9sTMygsMeLv4UyzAA8aeDgz68FuRDZ0JzpUDTM5OVj/Cm7XyAeAT1cmkJZdiI+bI90i/GgV7EX8lH4sfao3DT2dOZyWw5NztvPQd5t5Zu5OSo0aKw+kMWpGPM/9srPcPcgvKmXUjPXcMX29zYwpgL92p/LHzlMknc9nxqojfGHKsdmfksW+lKxq3eOjZ3L4bUdyhUGUELWpRkNCq1atYuLEiXTt2pWSkhJefPFFBg4cyL59+3B3d6/wmPXr13P33XczdepUbrnlFmbPns3w4cPZtm0bbduqqpTvvvsuH3/8Md999x0RERG8/PLLDBo0iH379uHiIt2SQlwvujbxRa9Tw0EXS7itLhdHA2+Yqt9euP2J/s341/w9ANwX0xhQib4NPZ05k12Il4sDd3QOtTnu/h5NCPV1o00jL4K9XS3bNU1V6f1laxLPzt3Fxhf7s940OyimaQPL9O0wPzeWPdUHnY5yaz2Ze1hSMgsAePjGSEv9Gp1OR1SgJ+/dEc24bzezZK+16u+Y7uHEmXpkVh44Q05hic3Cl3/sVENRALd/tg5vV0fyi0oZ2i7YMmQFMHtjoiUpGeD3nadoE1J5L9eGo+l8sPSQZQ2opwc05x/9oyrdX4jLVaMelsWLFzNu3DjatGlD+/btmTlzJomJiWzdWnlho48++ojBgwfz7LPP0qpVK9588006derEf//7X0D9j/7hhx/y0ksvMWzYMKKjo5k1axanTp1iwYIFl3VxQoirS1SgJ/Mf78mM+zpf8e8a1TmM3s0bEtsqkBtNuSc6nY7eUaq35J7ujXG/YMVrnU5HbOtAm2DFvP3ft7fDx82R9Nwitpw4z3LTtOTeUbZ5LXq9rsKFKc0BC4C3qyNjTUFUWX1bBPDMwOa0DPKkSQM3ADYcPWcJSIpKjZbZR6D+fp214Tig6r1ompqtVFhiZN72ZFIyCwj1dSU61NsSrPh7qAThhTvLF7sDKCk18uSc7Yz+YoPNgpVrTQFaTaVlFdD//+L45887yS+SXhpRucvKYcnMVMlsfn5+le4THx9PbGyszbZBgwYRHx8PwLFjx0hNTbXZx9vbm+7du1v2uVBhYSFZWVk2DyHEtaF9mE+5gOBKcHLQM+vBbnx1fxebmUZTbm7JOyPb8dSAmvUWODnoualFAADfbzjB3lNZ6HTQr2VAtY5v5OOKn7sTAON7RVTawzSpXxSLJ/fmvpgmAKw4cJoDqda/A5ftt9Zv2ZmUyZ7kLJwc9Pz0SAyrn72JpU/1Zu6jMdwQ6YeLo55/396Of/SzXusHd7bHwzQzafXhMxSVWHtdABbvTeW3HafQ6+DeG8KZ/VB39V0nMygsqXnAMXtTIkfO5PLrtiTu+iKeU6YaPOLiNE1j64lz9XqtrNp2ybOEjEYjkydPpmfPnpahnYqkpqYSGBhosy0wMJDU1FTL5+Ztle1zoalTp/L6669fatOFEKJS/h7O3NU1/JKO7d8qgPnbk1m4KwWATuG+NPBwruIoRafT8eLNrVh/5CwP9qp6hekbTEscmHtXDHqdJZ/FaNTQ6bAUurslOhg/dydLQAQwZ0IMpUYNg16HpmmM7xWBg0HHjVH+DGwdyLztyYz7djMG07IJA1oF8mjfpvyyVRWxe6xvU54d1BJN0/Bzd+JcbhF7krPo3Ni3WteraRqaBr9uU+dz0OvYlZTJwP+s5vkhLbm3e3i5nqhTGflMW3TAJkH6evXjppO8OH83d3UJ4507ou3dnDpxyQHLxIkT2bNnD2vXrq3N9lTLlClTePrppy3vs7KyCAsLq/N2CCFEWb2bN8RBr6PENJQS2yqwiiNs3dE5tFzeTGVaBnnh5eJgmSI9pG0Qqw6eIT23iF+2JrHhaDq/m6Zs33dD+eElwJJQrNPpeLlMteIHe0Ww4Wg6KVkFlBo1diVlsispk6Tz+ZYlBe7oHGY5tktjX/7ed5otx89VK2B5+qcdbDp+jgm9Izl5Lh8PZwd+fawHL8zbxfbEDF5esAcvFweGdWhkOUbTNJ7/dRdrDp/lTHYhN0y4fgOW4lIjn65MAGD5gdNomlbhMOO15pIClkmTJrFw4UJWr15NaOjF/+cKCgri9OnTNttOnz5NUFCQ5XPztuDgYJt9OnToUOE5nZ2dcXau3r9ahBCirni5ONI90o91CSqZdUDr6g0HXQqDXke3iAYs26/+fr0hsgEa8OeuFJ77dZdlnylDWtIxvHq9HmZtG3mzfkp/So0aKZn5LNyVwrRFB/hpi6pN07WJLxH+1okWXZv48fe+02w8do7UrAJSMgp4c3hb8opK+GDpIQqLjTT2d2N8zwicHQ3M35GMpsErv+0FVA9QiyBPfnm0B6/+vofvNyTy564Um4Bl4a4U1piWM9hzKvO6+ZGuyJ+7UizLV5zNKeLImdwrWpunvqhRwKJpGk888QTz588nLi6OiIiquy1jYmJYvnw5kydPtmxbunQpMTExAERERBAUFMTy5cstAUpWVhYbN27kscceq0nzhBDC7vq1DGRdQjqNG7jRtOGV/RG5IdLPErB0beJHx3AfzuUUcTanEDcnA1NubnVZQycGvY5QXzce7dOU/SlZ/LZD9diM6mzbo92liQqIyq5/tC8li5zCEsvUcYDzuUUMbB3EhSVezL1KBr2Ou7qE8/2GRNYlnKWoxIiTg56cwhKb9Z+yC0o4kZ5HE/+KZ6deyzRNs1Ru1uvAqKkZWxKwXGDixInMnj2b3377DU9PT0uOibe3N66uKklu7NixNGrUiKlTpwLw5JNP0qdPH/7v//6PoUOHMmfOHLZs2cIXX3wBqO7EyZMn89ZbbxEVFWWZ1hwSEsLw4cNr8VKFEOLKG901jIS0HIa0DbriPQA9TbObGrg7ERXggV6v48cJN1yR73rjtrbsOJlBUYmRm6ODbT5rE+KNi6OegmLrTKPEc2ptpnaNvLkxyp/P4o6wdN9py6reA1sHciankAbuzjbDSG1CvPD3cOJsThFbTpyjR1N/vll7jLTsQpo0cMPVyYH9KVnsTs6sNGBJzsjnp02JbD+ZwcDWgYzuFs6+U1nodTrahXpTWFLKkr2n6RTuQ6ivm82x+UWlPDxrC+7OBmbc27ne9eLsOJnBwdPZuDsZGN0tnK/XHmPD0XTurWTY71pSo4Bl+vTpAPTt29dm+7fffsu4ceMASExMRK+3Tj7q0aMHs2fP5qWXXuLFF18kKiqKBQsW2CTqPvfcc+Tm5jJhwgQyMjLo1asXixcvlhosQoirjruzA1NHtKuT72oV7MWMezsT5O1S6ZpKtcXbzZElk3sDqo5NWU4Oeno29Wf5gTQmx0ZxT/dwXvh1Nw09nHn1ttY4GfTM3pTI+bxifjYNKw2NDrYZ8jHTm1bgnrctmVUHz9Am2Jsv16iCdk8PbMHGo+nsT8liT3Imt7YPsRxXUmrkh42J/LYjme0nMyy9OGsOn+Xtv/ZbgqnYVoEkZ+SzPyWLxg3cWPZ0HxwN1t+st/7cZ5minZpVUCcz1mpiV5Kands9sgEDWweaApZz18UQWY2HhKoSFxdXbtuoUaMYNWpUpcfodDreeOMN3njjjZo0RwghrnuD2wbV2XddGKiU9f6o9iScyaFLY190Oh3fjOtq83n/loH8ui3Jsnr1xYaq+rYIYN62ZFYeTMOoaWQXlNAi0JNb2gWTX1TCDxuxrBEFavbQ5Dk7bBaIvCHSj25N/Pgu/gSZ+cW4OxkoLDFahtAATqTn8fOWk4zprnonlu07zQ9llldISMu5pIBlVvxxft2axIz7OlfreKNR48X5u3F1MvBqJauPm+0xXXfbEC/ah/ng7KDnbE4hR8/m1ngIcu+pTAx6HS2DLr+qdF2QxQ+FEEJcNl93J7q6V16Ta1CbQMsU5kh/94surtg7yh+9Dg6dzuHQ6RwAnhoQhV6vs6wxtTtZJd5m5BUz4rP1pGYV4OHswFMDmjO0XTBB3ur842+M5OiZHFoFe3EiPY+pi/bj5eJIkwZufLwigY+XH2Zkp1CcDHpe+0MlAZtneh1Jy+FGUyHB6io1any07DDpuUX8uDGRpwe2qPKYfSlZzNmsep5GdQ7DwaDjX/N380S/KMuyD2Z7TqmaO20aeePiaKBjuA8bjp5j+Kfr6NrEj3dGRtPQ03ZSyq6kDN76cz8vDW1FdKgPmqYxY9VR3l1yAE2Dbk38eHFoKzqE+dToWuuaLH4ohBDiiuvdvCGuph6a7lUkAvu4OdGvpZoS7u3qyIM9IxhkWoSyeaAnTg56S+Lti/N3k5pVQJMGbix8ohfje0VYghXz8R3DfXFxNNAiyJOZD3Tj47s7MrFfMxr5uHI6q5D/xZ9gw9F0ks7n4+niYFmqIeFMjuU8+1OymDJvF2lZBeXam5CWw7Nzd7LxaDo7TmaQbko0/nN3SrmRiVKjxtrDZykuswzChjJLJCzYkcy0RQfYfPw8b/+53+b4guJSDp/OBqyLg97VNQwHvY7sghJWHEjjpQW7ycwv5umfd/D5KpWc++Gyw2w6ds6yVtSbC/fzzmIVrOh1sOn4OR6cuZn0nELLd6k6Oeq784tKuXNGPDNWHSlXSLAuSQ+LEEKIK87F0cAt0cHM3ZpUrWGsGfd24lxuEQ09nW1yMxwNeloFebIzKZMnftzO7uRMHPQ6Prm7U41mDTk7GHgyNornftnFZ3EJdG2ieodubR9CW9MaSglp1oDl1d/2sun4OQqLjXxwVwfL9pUH0/jH7O1kF5awNuEst5RJSD5yJpdDp3NoEeRp2fafpYf478oExnQP5+3bVa5T/BFrwDJnU6Klts7B09lsS8ywJCUfTM2mxKgK9YWYgrLbO4YyuE0w2xLPc/83m1iy9zR7kteQnJGPTge9ovxZY1quIf5IOhl5RXwXfxyA129rw6A2QYz7dhMHUrN59fe9/PeeTmiaxuM/bGPz8fP8+Y9ebD1xnk3Hz5GSlc8jvSOrfY9rm/SwCCGEqBNvDm/Lsqd706d51cMsDgY9AV4uFSaSmoMLcx7L0wOb0y608oUaKzOiYyMiG7pzPq+Yv/ep3JaRnUJpapoinJCWC8Dxs7mW/Jjfd54iNbOAohIj7yw+wIMzN5NtKo+fklnAt+uOA1gWoPxzd4rl+7IKivluvfp8zuaTHD+bS6lRs6zJ5KDXWYIV82X/uMmaU7PnlLreNiFeNvfF1clAz2b+PH5TMwBLjRZNg0mzt1tWH0/PLeKL1UcpNWq0CPTk/h5NCPJ24b072mPQ61i4K4W/dqewNuEsi/akcjankLlbTvKX6Rpubhts18ReCViEEELUCRdHA80CPKvesQqTBzTn/VHteeWW1rw/qj2P9m56SedxMOj55wBrjkmkvzudwn1o2lD11JzNKSQzr9iyHAFAiVFj2qL9jJy+nulxR9A0uLtbOM8OamH53KDX8c+BzQH4a7d1EcnvN5ywBDelRo0Plx1i76lMsgtL8HRxYFQXayHWFwa3BGDhrlNkFRQDsCdZ5a+Yh4MuNOmmZvRo2oBmAR48bzr+2Nlcm32+Ni3X0L+Vtahhu1BvS8/Js3N38vof1po3c7cmWerr3NzOdjp7XZOARQghxFXFw9mBOzqH8mCvCO7oHHpZU7qHtA2iTYiaJTOycyg6nQ5PF0eCTEnBh9OyLcnCt3dU07AX7DjF7uRMvF0dmT6mE1NHtOP+Hk3wdlULVnZu7MvIziqRNyEth9FfbuDnzSctazuNN60V9dvOU3yyQpXY7x7hxz3dGuOg1xET2YAJvSOJCvCgoNjIHFMvi3WGUMUBi5ODnh8e6s7Sp3rz8I0RlmEjgBGdVNsLTTko/S9YNuKpAc25IdKP3KJSEtJycHMy4Opo4ER6HnlFpTTycbVZUdweJGARQghx3dLrdXx+X2deGtqKh260Vm9vGqB6Wb5YfZSUzAK8XR2ZOqIdUabhop7NGrBkcm+GmHodPJwdmGQakrmrSxheLmp/V0cDm46d47lfd3E2p4hGPq68MKQlwzqEoGmwdJ91aYV2od7EPduXr8d1QafT8fCNqtfj05VH2HrivGVV7raNKp+GrNPp0Ol0OBj03NNdLeLZMsiTsabVvUEVGrxwRpCjQc9nYzoT5qemYT/YM8Im1+jmdle+EGJVJOlWCCHEdS3U142HbrRNJm3W0IN1CemW3JY7u4Ti4mjgh4e6c/B0Nj2b+pfr2Xm4dyS3d2qEv2mF7pGdQ+kW4cd/lh3iTHYhgV4u3NM9HEeDnndGRhPs7coXq49g1LBMny5beXdk51C+XnuMg6ezufPzeEqNGjdE+hHuZ1udtzIP3RhJYYmRAa0DaR3shaezA9mFJdzUMsCy8GVZfu5O/DQhhpUH0xjVOYyNx9KZvz0ZwBKY2ZNOq041uHouKysLb29vMjMz8fK6OgrgCCGEqL/+F3+cl02LM7YM8mT+4z1xdaq8cN6lOpiaTVp2QaX1XlYdOsP932wCIMTbhd8m9SpXZ6W6/vnzTn7dlsT347vTK8q/yv1LjRqPfb8VB4OO/97d6YpUU67J77cELEIIIcQFtp44x8jp8Xg4O/D7pJ5EXuGFLC9m0uxtrE04y/8e7H5Js6HM8otKOZWZf8UX5awJCViEEEKIy6BpGr9sTaJVsFels3LqUqlp9tG1pia/35LDIoQQQlxAp9MxqkuYvZthcS0GKzUls4SEEEIIUe9JwCKEEEKIek8CFiGEEELUexKwCCGEEKLek4BFCCGEEPWeBCxCCCGEqPckYBFCCCFEvScBixBCCCHqPQlYhBBCCFHvScAihBBCiHpPAhYhhBBC1HsSsAghhBCi3pOARQghhBD13jWxWrOmaYBaploIIYQQVwfz77b5d/xiromAJTs7G4CwsPqzFLgQQgghqic7Oxtvb++L7qPTqhPW1HNGo5FTp07h6emJTqer1XNnZWURFhbGyZMn8fLyqtVzCyu5z3VH7nXdkXtdN+Q+153avteappGdnU1ISAh6/cWzVK6JHha9Xk9oaOgV/Q4vLy/5H6EOyH2uO3Kv647c67oh97nu1Oa9rqpnxUySboUQQghR70nAIoQQQoh6TwKWKjg7O/Pqq6/i7Oxs76Zc0+Q+1x2513VH7nXdkPtcd+x5r6+JpFshhBBCXNukh0UIIYQQ9Z4ELEIIIYSo9yRgEUIIIUS9JwGLEEIIIeo9CVgu4tNPP6VJkya4uLjQvXt3Nm3aZO8mXfVee+01dDqdzaNly5aWzwsKCpg4cSINGjTAw8ODkSNHcvr0aTu2+OqwevVqbr31VkJCQtDpdCxYsMDmc03TeOWVVwgODsbV1ZXY2FgOHz5ss8+5c+cYM2YMXl5e+Pj4MH78eHJycurwKq4OVd3rcePGlfszPnjwYJt95F5XberUqXTt2hVPT08CAgIYPnw4Bw8etNmnOn9fJCYmMnToUNzc3AgICODZZ5+lpKSkLi+lXqvOfe7bt2+5P9OPPvqozT51cZ8lYKnETz/9xNNPP82rr77Ktm3baN++PYMGDSItLc3eTbvqtWnThpSUFMtj7dq1ls+eeuop/vjjD+bOncuqVas4deoUI0aMsGNrrw65ubm0b9+eTz/9tMLP3333XT7++GNmzJjBxo0bcXd3Z9CgQRQUFFj2GTNmDHv37mXp0qUsXLiQ1atXM2HChLq6hKtGVfcaYPDgwTZ/xn/88Uebz+VeV23VqlVMnDiRDRs2sHTpUoqLixk4cCC5ubmWfar6+6K0tJShQ4dSVFTE+vXr+e6775g5cyavvPKKPS6pXqrOfQZ4+OGHbf5Mv/vuu5bP6uw+a6JC3bp10yZOnGh5X1paqoWEhGhTp061Y6uufq+++qrWvn37Cj/LyMjQHB0dtblz51q27d+/XwO0+Pj4Omrh1Q/Q5s+fb3lvNBq1oKAg7b333rNsy8jI0JydnbUff/xR0zRN27dvnwZomzdvtuyzaNEiTafTacnJyXXW9qvNhfda0zTt/vvv14YNG1bpMXKvL01aWpoGaKtWrdI0rXp/X/z111+aXq/XUlNTLftMnz5d8/Ly0goLC+v2Aq4SF95nTdO0Pn36aE8++WSlx9TVfZYelgoUFRWxdetWYmNjLdv0ej2xsbHEx8fbsWXXhsOHDxMSEkJkZCRjxowhMTERgK1bt1JcXGxz31u2bEl4eLjc98tw7NgxUlNTbe6rt7c33bt3t9zX+Ph4fHx86NKli2Wf2NhY9Ho9GzdurPM2X+3i4uIICAigRYsWPPbYY6Snp1s+k3t9aTIzMwHw8/MDqvf3RXx8PO3atSMwMNCyz6BBg8jKymLv3r112Pqrx4X32eyHH37A39+ftm3bMmXKFPLy8iyf1dV9viYWP6xtZ8+epbS01ObmAwQGBnLgwAE7tera0L17d2bOnEmLFi1ISUnh9ddf58Ybb2TPnj2kpqbi5OSEj4+PzTGBgYGkpqbap8HXAPO9q+jPs/mz1NRUAgICbD53cHDAz89P7n0NDR48mBEjRhAREcGRI0d48cUXGTJkCPHx8RgMBrnXl8BoNDJ58mR69uxJ27ZtAar190VqamqFf+7NnwlbFd1ngHvuuYfGjRsTEhLCrl27eP755zl48CDz5s0D6u4+S8Ai6tSQIUMsr6Ojo+nevTuNGzfm559/xtXV1Y4tE6J2jB492vK6Xbt2REdH07RpU+Li4ujfv78dW3b1mjhxInv27LHJdxO1r7L7XDa/ql27dgQHB9O/f3+OHDlC06ZN66x9MiRUAX9/fwwGQ7ls89OnTxMUFGSnVl2bfHx8aN68OQkJCQQFBVFUVERGRobNPnLfL4/53l3sz3NQUFC5hPKSkhLOnTsn9/4yRUZG4u/vT0JCAiD3uqYmTZrEwoULWblyJaGhoZbt1fn7IigoqMI/9+bPhFVl97ki3bt3B7D5M10X91kClgo4OTnRuXNnli9fbtlmNBpZvnw5MTExdmzZtScnJ4cjR44QHBxM586dcXR0tLnvBw8eJDExUe77ZYiIiCAoKMjmvmZlZbFx40bLfY2JiSEjI4OtW7da9lmxYgVGo9Hyl5O4NElJSaSnpxMcHAzIva4uTdOYNGkS8+fPZ8WKFURERNh8Xp2/L2JiYti9e7dNgLh06VK8vLxo3bp13VxIPVfVfa7Ijh07AGz+TNfJfa619N1rzJw5czRnZ2dt5syZ2r59+7QJEyZoPj4+NlnQoub++c9/anFxcdqxY8e0devWabGxsZq/v7+WlpamaZqmPfroo1p4eLi2YsUKbcuWLVpMTIwWExNj51bXf9nZ2dr27du17du3a4D2wQcfaNu3b9dOnDihaZqmTZs2TfPx8dF+++03bdeuXdqwYcO0iIgILT8/33KOwYMHax07dtQ2btyorV27VouKitLuvvtue11SvXWxe52dna0988wzWnx8vHbs2DFt2bJlWqdOnbSoqCitoKDAcg6511V77LHHNG9vby0uLk5LSUmxPPLy8iz7VPX3RUlJida2bVtt4MCB2o4dO7TFixdrDRs21KZMmWKPS6qXqrrPCQkJ2htvvKFt2bJFO3bsmPbbb79pkZGRWu/evS3nqKv7LAHLRXzyySdaeHi45uTkpHXr1k3bsGGDvZt01bvrrru04OBgzcnJSWvUqJF21113aQkJCZbP8/Pztccff1zz9fXV3NzctNtvv11LSUmxY4uvDitXrtSAco/7779f0zQ1tfnll1/WAgMDNWdnZ61///7awYMHbc6Rnp6u3X333ZqHh4fm5eWlPfDAA1p2drYdrqZ+u9i9zsvL0wYOHKg1bNhQc3R01Bo3bqw9/PDD5f6hI/e6ahXdY0D79ttvLftU5++L48ePa0OGDNFcXV01f39/7Z///KdWXFxcx1dTf1V1nxMTE7XevXtrfn5+mrOzs9asWTPt2Wef1TIzM23OUxf3WWdqsBBCCCFEvSU5LEIIIYSo9yRgEUIIIUS9JwGLEEIIIeo9CViEEEIIUe9JwCKEEEKIek8CFiGEEELUexKwCCGEEKLek4BFCCGEEPWeBCxCCCGEqPckYBFCCCFEvScBixBCCCHqPQlYhBBCCFHv/T8rP9uCAQ26wwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "P-NcEWtYcM7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, prompts: str, params: ModelArgs, max_gen_len: int=500, temperature: float = 0.6, top_p: float = 0.9):\n",
        "    bsz = 1  #For inferencing, in general user just input one prompt which we'll take it as 1-batch\n",
        "    prompt_tokens = token_bos.tolist() + encode(prompts)\n",
        "    assert len(prompt_tokens) <= params.max_seq_len, \"prompt token length should be small than max_seq_len\"\n",
        "    total_len = min(len(prompt_tokens)+max_gen_len, params.max_seq_len)\n",
        "\n",
        "    tokens = torch.full((bsz,total_len), fill_value=token_pad.item(), dtype=torch.long, device=params.device)\n",
        "\n",
        "    tokens[:,:len(prompt_tokens)] = torch.tensor(prompt_tokens, dtype=torch.long, device=params.device)\n",
        "\n",
        "    input_text_mask = tokens != token_pad.item()\n",
        "\n",
        "    prev_pos = 0\n",
        "    for cur_pos in range(1, total_len):\n",
        "      with torch.no_grad():\n",
        "        logits, _ = model(x=tokens[:,prev_pos:cur_pos], start_pos=prev_pos)\n",
        "      if temperature > 0:\n",
        "        probs = torch.softmax(logits[:, -1]/temperature, dim=-1)\n",
        "        next_token = sample_top_p(probs, top_p)\n",
        "      else:\n",
        "        next_token = torch.argmax(logits[:, -1], dim=-1)\n",
        "\n",
        "      next_token = next_token.reshape(-1)\n",
        "\n",
        "      # only replace the token if it's a padding token\n",
        "      next_token = torch.where(input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token)\n",
        "      tokens[:, cur_pos] = next_token\n",
        "\n",
        "      prev_pos = cur_pos\n",
        "      if tokens[:,cur_pos]==token_pad.item() and next_token == token_eos.item():\n",
        "        break\n",
        "\n",
        "    output_tokens, output_texts = [], []\n",
        "\n",
        "    for i, toks in enumerate(tokens.tolist()):\n",
        "      if token_eos.item() in toks:\n",
        "        eos_idx = toks.index(token_eos.item())\n",
        "        toks = toks[:eos_idx]\n",
        "\n",
        "      output_tokens.append(toks)\n",
        "      output_texts.append(decode(toks))\n",
        "    return output_tokens, output_texts\n",
        "\n",
        "# Perform top-p (nucleus) sampling on a probability distribution.\n",
        "def sample_top_p(probs, p):\n",
        "    probs_sort, prob_idx = torch.sort(probs, dim=-1, descending=True)\n",
        "    probs_sum = torch.cumsum(probs_sort, dim=-1)\n",
        "    mask = probs_sum - probs_sort > p\n",
        "    probs_sort[mask] = 0.0\n",
        "    probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n",
        "    next_token = torch.multinomial(probs_sort, num_samples=1)\n",
        "    next_token = torch.gather(prob_idx, -1, next_token)\n",
        "    # Sampled token indices from the vocabular is returned\n",
        "    return next_token"
      ],
      "metadata": {
        "id": "k7acQUYFbP8I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = \"Consider you what services he has done\"\n",
        "output_tokens, output_texts = generate(model, prompts, ModelArgs)\n",
        "output_texts = output_texts[0].replace(\"<|begin_of_text|>\", \"\")\n",
        "print(output_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kutheexWcagU",
        "outputId": "c84beb0e-26a9-4f80-d6ef-711c7315f124"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider you what services he has done\n",
            "ee adetrdie frml ngnros eee o astrceto,AdT\n",
            "hu athrgtttwr hm i hmrs o orcaie,Wrnhhpad hsln\n",
            "o i amndigtou o orslwt eeeig,ai ntslegetrut\n",
            "ee frml eeee fo hrg nratrae eer nr oe\n",
            "nte o epry hmtnns rnos n ore o i oe nt awk\n",
            "o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwB8sywPckXh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}